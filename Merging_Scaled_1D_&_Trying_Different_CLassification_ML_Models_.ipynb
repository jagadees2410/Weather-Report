{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jagadees2410/Weather-Report/blob/main/Merging_Scaled_1D_%26_Trying_Different_CLassification_ML_Models_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXx7SoC7qyRv"
      },
      "source": [
        "### **WORKING ON COMBING MULTIPLE LEAD FILES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI0sFzAqPP8g"
      },
      "source": [
        "#importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os \n",
        "from natsort import natsorted\n",
        "\n",
        "#creating list to store file_names\n",
        "NORMAL_=[]\n",
        "MI_=[]\n",
        "PMI_=[]\n",
        "HB_=[]\n",
        "\n",
        "normal = '/NORMAL'\n",
        "abnormal = '/AHB'\n",
        "MI = '/MI'\n",
        "MI_history = '/PM'\n",
        "\n",
        "Types_ECG = {'normal':normal,'Abnormal_hear_beat':abnormal,'MI':MI,'History_MI':MI_history}\n",
        "\n",
        "for types,folder in Types_ECG.items():\n",
        "  for files in os.listdir(folder):\n",
        "    if types=='normal':\n",
        "      NORMAL_.append(files)\n",
        "    elif types=='Abnormal_hear_beat':\n",
        "      HB_.append(files)\n",
        "    elif types=='MI':\n",
        "      MI_.append(files)\n",
        "    elif types=='History_MI':\n",
        "      PMI_.append(files)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJL9qAFSUOsN",
        "outputId": "9d09f4bf-aef2-474d-8b41-7ad9ac01c850"
      },
      "source": [
        "NORMAL_.sort()\n",
        "NORMAL_"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Normal(1).jpg',\n",
              " 'Normal(10).jpg',\n",
              " 'Normal(100).jpg',\n",
              " 'Normal(101).jpg',\n",
              " 'Normal(102).jpg',\n",
              " 'Normal(103).jpg',\n",
              " 'Normal(104).jpg',\n",
              " 'Normal(105).jpg',\n",
              " 'Normal(106).jpg',\n",
              " 'Normal(107).jpg',\n",
              " 'Normal(108).jpg',\n",
              " 'Normal(109).jpg',\n",
              " 'Normal(11).jpg',\n",
              " 'Normal(110).jpg',\n",
              " 'Normal(111).jpg',\n",
              " 'Normal(112).jpg',\n",
              " 'Normal(113).jpg',\n",
              " 'Normal(114).jpg',\n",
              " 'Normal(115).jpg',\n",
              " 'Normal(116).jpg',\n",
              " 'Normal(117).jpg',\n",
              " 'Normal(118).jpg',\n",
              " 'Normal(119).jpg',\n",
              " 'Normal(12).jpg',\n",
              " 'Normal(120).jpg',\n",
              " 'Normal(121).jpg',\n",
              " 'Normal(122).jpg',\n",
              " 'Normal(123).jpg',\n",
              " 'Normal(124).jpg',\n",
              " 'Normal(125).jpg',\n",
              " 'Normal(126).jpg',\n",
              " 'Normal(127).jpg',\n",
              " 'Normal(128).jpg',\n",
              " 'Normal(129).jpg',\n",
              " 'Normal(13).jpg',\n",
              " 'Normal(130).jpg',\n",
              " 'Normal(131).jpg',\n",
              " 'Normal(132).jpg',\n",
              " 'Normal(133).jpg',\n",
              " 'Normal(134).jpg',\n",
              " 'Normal(135).jpg',\n",
              " 'Normal(136).jpg',\n",
              " 'Normal(137).jpg',\n",
              " 'Normal(138).jpg',\n",
              " 'Normal(139).jpg',\n",
              " 'Normal(14).jpg',\n",
              " 'Normal(140).jpg',\n",
              " 'Normal(141).jpg',\n",
              " 'Normal(142).jpg',\n",
              " 'Normal(143).jpg',\n",
              " 'Normal(144).jpg',\n",
              " 'Normal(145).jpg',\n",
              " 'Normal(146).jpg',\n",
              " 'Normal(147).jpg',\n",
              " 'Normal(148).jpg',\n",
              " 'Normal(149).jpg',\n",
              " 'Normal(15).jpg',\n",
              " 'Normal(150).jpg',\n",
              " 'Normal(151).jpg',\n",
              " 'Normal(152).jpg',\n",
              " 'Normal(153).jpg',\n",
              " 'Normal(154).jpg',\n",
              " 'Normal(155).jpg',\n",
              " 'Normal(156).jpg',\n",
              " 'Normal(157).jpg',\n",
              " 'Normal(158).jpg',\n",
              " 'Normal(159).jpg',\n",
              " 'Normal(16).jpg',\n",
              " 'Normal(160).jpg',\n",
              " 'Normal(161).jpg',\n",
              " 'Normal(162).jpg',\n",
              " 'Normal(163).jpg',\n",
              " 'Normal(164).jpg',\n",
              " 'Normal(165).jpg',\n",
              " 'Normal(166).jpg',\n",
              " 'Normal(167).jpg',\n",
              " 'Normal(168).jpg',\n",
              " 'Normal(169).jpg',\n",
              " 'Normal(17).jpg',\n",
              " 'Normal(170).jpg',\n",
              " 'Normal(171).jpg',\n",
              " 'Normal(172).jpg',\n",
              " 'Normal(173).jpg',\n",
              " 'Normal(174).jpg',\n",
              " 'Normal(175).jpg',\n",
              " 'Normal(176).jpg',\n",
              " 'Normal(177).jpg',\n",
              " 'Normal(178).jpg',\n",
              " 'Normal(179).jpg',\n",
              " 'Normal(18).jpg',\n",
              " 'Normal(180).jpg',\n",
              " 'Normal(181).jpg',\n",
              " 'Normal(182).jpg',\n",
              " 'Normal(183).jpg',\n",
              " 'Normal(184).jpg',\n",
              " 'Normal(185).jpg',\n",
              " 'Normal(186).jpg',\n",
              " 'Normal(187).jpg',\n",
              " 'Normal(188).jpg',\n",
              " 'Normal(189).jpg',\n",
              " 'Normal(19).jpg',\n",
              " 'Normal(190).jpg',\n",
              " 'Normal(191).jpg',\n",
              " 'Normal(192).jpg',\n",
              " 'Normal(193).jpg',\n",
              " 'Normal(194).jpg',\n",
              " 'Normal(195).jpg',\n",
              " 'Normal(196).jpg',\n",
              " 'Normal(197).jpg',\n",
              " 'Normal(198).jpg',\n",
              " 'Normal(199).jpg',\n",
              " 'Normal(2).jpg',\n",
              " 'Normal(20).jpg',\n",
              " 'Normal(200).jpg',\n",
              " 'Normal(201).jpg',\n",
              " 'Normal(202).jpg',\n",
              " 'Normal(203).jpg',\n",
              " 'Normal(204).jpg',\n",
              " 'Normal(205).jpg',\n",
              " 'Normal(206).jpg',\n",
              " 'Normal(207).jpg',\n",
              " 'Normal(208).jpg',\n",
              " 'Normal(209).jpg',\n",
              " 'Normal(21).jpg',\n",
              " 'Normal(210).jpg',\n",
              " 'Normal(211).jpg',\n",
              " 'Normal(212).jpg',\n",
              " 'Normal(213).jpg',\n",
              " 'Normal(214).jpg',\n",
              " 'Normal(215).jpg',\n",
              " 'Normal(216).jpg',\n",
              " 'Normal(217).jpg',\n",
              " 'Normal(218).jpg',\n",
              " 'Normal(219).jpg',\n",
              " 'Normal(22).jpg',\n",
              " 'Normal(220).jpg',\n",
              " 'Normal(221).jpg',\n",
              " 'Normal(222).jpg',\n",
              " 'Normal(223).jpg',\n",
              " 'Normal(224).jpg',\n",
              " 'Normal(225).jpg',\n",
              " 'Normal(226).jpg',\n",
              " 'Normal(227).jpg',\n",
              " 'Normal(228).jpg',\n",
              " 'Normal(229).jpg',\n",
              " 'Normal(23).jpg',\n",
              " 'Normal(230).jpg',\n",
              " 'Normal(231).jpg',\n",
              " 'Normal(232).jpg',\n",
              " 'Normal(233).jpg',\n",
              " 'Normal(234).jpg',\n",
              " 'Normal(235).jpg',\n",
              " 'Normal(236).jpg',\n",
              " 'Normal(237).jpg',\n",
              " 'Normal(238).jpg',\n",
              " 'Normal(239).jpg',\n",
              " 'Normal(24).jpg',\n",
              " 'Normal(240).jpg',\n",
              " 'Normal(241).jpg',\n",
              " 'Normal(242).jpg',\n",
              " 'Normal(243).jpg',\n",
              " 'Normal(244).jpg',\n",
              " 'Normal(245).jpg',\n",
              " 'Normal(246).jpg',\n",
              " 'Normal(247).jpg',\n",
              " 'Normal(248).jpg',\n",
              " 'Normal(249).jpg',\n",
              " 'Normal(25).jpg',\n",
              " 'Normal(250).jpg',\n",
              " 'Normal(251).jpg',\n",
              " 'Normal(252).jpg',\n",
              " 'Normal(253).jpg',\n",
              " 'Normal(254).jpg',\n",
              " 'Normal(255).jpg',\n",
              " 'Normal(256).jpg',\n",
              " 'Normal(257).jpg',\n",
              " 'Normal(258).jpg',\n",
              " 'Normal(259).jpg',\n",
              " 'Normal(26).jpg',\n",
              " 'Normal(260).jpg',\n",
              " 'Normal(261).jpg',\n",
              " 'Normal(262).jpg',\n",
              " 'Normal(263).jpg',\n",
              " 'Normal(264).jpg',\n",
              " 'Normal(265).jpg',\n",
              " 'Normal(266).jpg',\n",
              " 'Normal(267).jpg',\n",
              " 'Normal(268).jpg',\n",
              " 'Normal(269).jpg',\n",
              " 'Normal(27).jpg',\n",
              " 'Normal(270).jpg',\n",
              " 'Normal(271).jpg',\n",
              " 'Normal(272).jpg',\n",
              " 'Normal(273).jpg',\n",
              " 'Normal(274).jpg',\n",
              " 'Normal(275).jpg',\n",
              " 'Normal(276).jpg',\n",
              " 'Normal(277).jpg',\n",
              " 'Normal(278).jpg',\n",
              " 'Normal(279).jpg',\n",
              " 'Normal(28).jpg',\n",
              " 'Normal(280).jpg',\n",
              " 'Normal(281).jpg',\n",
              " 'Normal(282).jpg',\n",
              " 'Normal(283).jpg',\n",
              " 'Normal(284).jpg',\n",
              " 'Normal(29).jpg',\n",
              " 'Normal(3).jpg',\n",
              " 'Normal(30).jpg',\n",
              " 'Normal(31).jpg',\n",
              " 'Normal(32).jpg',\n",
              " 'Normal(33).jpg',\n",
              " 'Normal(34).jpg',\n",
              " 'Normal(35).jpg',\n",
              " 'Normal(36).jpg',\n",
              " 'Normal(37).jpg',\n",
              " 'Normal(38).jpg',\n",
              " 'Normal(39).jpg',\n",
              " 'Normal(4).jpg',\n",
              " 'Normal(40).jpg',\n",
              " 'Normal(41).jpg',\n",
              " 'Normal(42).jpg',\n",
              " 'Normal(43).jpg',\n",
              " 'Normal(44).jpg',\n",
              " 'Normal(45).jpg',\n",
              " 'Normal(46).jpg',\n",
              " 'Normal(47).jpg',\n",
              " 'Normal(48).jpg',\n",
              " 'Normal(49).jpg',\n",
              " 'Normal(5).jpg',\n",
              " 'Normal(50).jpg',\n",
              " 'Normal(51).jpg',\n",
              " 'Normal(52).jpg',\n",
              " 'Normal(53).jpg',\n",
              " 'Normal(54).jpg',\n",
              " 'Normal(55).jpg',\n",
              " 'Normal(56).jpg',\n",
              " 'Normal(57).jpg',\n",
              " 'Normal(58).jpg',\n",
              " 'Normal(59).jpg',\n",
              " 'Normal(6).jpg',\n",
              " 'Normal(60).jpg',\n",
              " 'Normal(61).jpg',\n",
              " 'Normal(62).jpg',\n",
              " 'Normal(63).jpg',\n",
              " 'Normal(64).jpg',\n",
              " 'Normal(65).jpg',\n",
              " 'Normal(66).jpg',\n",
              " 'Normal(67).jpg',\n",
              " 'Normal(68).jpg',\n",
              " 'Normal(69).jpg',\n",
              " 'Normal(7).jpg',\n",
              " 'Normal(70).jpg',\n",
              " 'Normal(71).jpg',\n",
              " 'Normal(72).jpg',\n",
              " 'Normal(73).jpg',\n",
              " 'Normal(74).jpg',\n",
              " 'Normal(75).jpg',\n",
              " 'Normal(76).jpg',\n",
              " 'Normal(77).jpg',\n",
              " 'Normal(78).jpg',\n",
              " 'Normal(79).jpg',\n",
              " 'Normal(8).jpg',\n",
              " 'Normal(80).jpg',\n",
              " 'Normal(81).jpg',\n",
              " 'Normal(82).jpg',\n",
              " 'Normal(83).jpg',\n",
              " 'Normal(84).jpg',\n",
              " 'Normal(85).jpg',\n",
              " 'Normal(86).jpg',\n",
              " 'Normal(87).jpg',\n",
              " 'Normal(88).jpg',\n",
              " 'Normal(89).jpg',\n",
              " 'Normal(9).jpg',\n",
              " 'Normal(90).jpg',\n",
              " 'Normal(91).jpg',\n",
              " 'Normal(92).jpg',\n",
              " 'Normal(93).jpg',\n",
              " 'Normal(94).jpg',\n",
              " 'Normal(95).jpg',\n",
              " 'Normal(96).jpg',\n",
              " 'Normal(97).jpg',\n",
              " 'Normal(98).jpg',\n",
              " 'Normal(99).jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRbNR2HEUkvU",
        "outputId": "70142582-f13b-479f-9dc6-88dc65681b2a"
      },
      "source": [
        "MI_.sort()\n",
        "MI_"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MI(1).jpg',\n",
              " 'MI(10).jpg',\n",
              " 'MI(100).jpg',\n",
              " 'MI(101).jpg',\n",
              " 'MI(102).jpg',\n",
              " 'MI(103).jpg',\n",
              " 'MI(104).jpg',\n",
              " 'MI(105).jpg',\n",
              " 'MI(106).jpg',\n",
              " 'MI(107).jpg',\n",
              " 'MI(108).jpg',\n",
              " 'MI(109).jpg',\n",
              " 'MI(11).jpg',\n",
              " 'MI(110).jpg',\n",
              " 'MI(111).jpg',\n",
              " 'MI(112).jpg',\n",
              " 'MI(113).jpg',\n",
              " 'MI(114).jpg',\n",
              " 'MI(115).jpg',\n",
              " 'MI(116).jpg',\n",
              " 'MI(117).jpg',\n",
              " 'MI(118).jpg',\n",
              " 'MI(119).jpg',\n",
              " 'MI(12).jpg',\n",
              " 'MI(120).jpg',\n",
              " 'MI(121).jpg',\n",
              " 'MI(122).jpg',\n",
              " 'MI(123).jpg',\n",
              " 'MI(124).jpg',\n",
              " 'MI(125).jpg',\n",
              " 'MI(126).jpg',\n",
              " 'MI(127).jpg',\n",
              " 'MI(128).jpg',\n",
              " 'MI(129).jpg',\n",
              " 'MI(13).jpg',\n",
              " 'MI(130).jpg',\n",
              " 'MI(131).jpg',\n",
              " 'MI(132).jpg',\n",
              " 'MI(133).jpg',\n",
              " 'MI(134).jpg',\n",
              " 'MI(135).jpg',\n",
              " 'MI(136).jpg',\n",
              " 'MI(137).jpg',\n",
              " 'MI(138).jpg',\n",
              " 'MI(139).jpg',\n",
              " 'MI(14).jpg',\n",
              " 'MI(140).jpg',\n",
              " 'MI(141).jpg',\n",
              " 'MI(142).jpg',\n",
              " 'MI(143).jpg',\n",
              " 'MI(144).jpg',\n",
              " 'MI(145).jpg',\n",
              " 'MI(146).jpg',\n",
              " 'MI(147).jpg',\n",
              " 'MI(148).jpg',\n",
              " 'MI(149).jpg',\n",
              " 'MI(15).jpg',\n",
              " 'MI(150).jpg',\n",
              " 'MI(151).jpg',\n",
              " 'MI(152).jpg',\n",
              " 'MI(153).jpg',\n",
              " 'MI(154).jpg',\n",
              " 'MI(155).jpg',\n",
              " 'MI(156).jpg',\n",
              " 'MI(157).jpg',\n",
              " 'MI(158).jpg',\n",
              " 'MI(159).jpg',\n",
              " 'MI(16).jpg',\n",
              " 'MI(160).jpg',\n",
              " 'MI(161).jpg',\n",
              " 'MI(162).jpg',\n",
              " 'MI(163).jpg',\n",
              " 'MI(164).jpg',\n",
              " 'MI(165).jpg',\n",
              " 'MI(166).jpg',\n",
              " 'MI(167).jpg',\n",
              " 'MI(168).jpg',\n",
              " 'MI(169).jpg',\n",
              " 'MI(17).jpg',\n",
              " 'MI(170).jpg',\n",
              " 'MI(171).jpg',\n",
              " 'MI(172).jpg',\n",
              " 'MI(173).jpg',\n",
              " 'MI(174).jpg',\n",
              " 'MI(175).jpg',\n",
              " 'MI(176).jpg',\n",
              " 'MI(177).jpg',\n",
              " 'MI(178).jpg',\n",
              " 'MI(179).jpg',\n",
              " 'MI(18).jpg',\n",
              " 'MI(180).jpg',\n",
              " 'MI(181).jpg',\n",
              " 'MI(182).jpg',\n",
              " 'MI(183).jpg',\n",
              " 'MI(184).jpg',\n",
              " 'MI(185).jpg',\n",
              " 'MI(186).jpg',\n",
              " 'MI(187).jpg',\n",
              " 'MI(188).jpg',\n",
              " 'MI(189).jpg',\n",
              " 'MI(19).jpg',\n",
              " 'MI(190).jpg',\n",
              " 'MI(191).jpg',\n",
              " 'MI(192).jpg',\n",
              " 'MI(193).jpg',\n",
              " 'MI(194).jpg',\n",
              " 'MI(195).jpg',\n",
              " 'MI(196).jpg',\n",
              " 'MI(197).jpg',\n",
              " 'MI(198).jpg',\n",
              " 'MI(199).jpg',\n",
              " 'MI(2).jpg',\n",
              " 'MI(20).jpg',\n",
              " 'MI(200).jpg',\n",
              " 'MI(201).jpg',\n",
              " 'MI(202).jpg',\n",
              " 'MI(203).jpg',\n",
              " 'MI(204).jpg',\n",
              " 'MI(205).jpg',\n",
              " 'MI(206).jpg',\n",
              " 'MI(207).jpg',\n",
              " 'MI(208).jpg',\n",
              " 'MI(209).jpg',\n",
              " 'MI(21).jpg',\n",
              " 'MI(210).jpg',\n",
              " 'MI(211).jpg',\n",
              " 'MI(212).jpg',\n",
              " 'MI(213).jpg',\n",
              " 'MI(214).jpg',\n",
              " 'MI(216).jpg',\n",
              " 'MI(217).jpg',\n",
              " 'MI(218).jpg',\n",
              " 'MI(219).jpg',\n",
              " 'MI(22).jpg',\n",
              " 'MI(220).jpg',\n",
              " 'MI(221).jpg',\n",
              " 'MI(222).jpg',\n",
              " 'MI(223).jpg',\n",
              " 'MI(224).jpg',\n",
              " 'MI(225).jpg',\n",
              " 'MI(226).jpg',\n",
              " 'MI(227).jpg',\n",
              " 'MI(228).jpg',\n",
              " 'MI(229).jpg',\n",
              " 'MI(23).jpg',\n",
              " 'MI(230).jpg',\n",
              " 'MI(231).jpg',\n",
              " 'MI(232).jpg',\n",
              " 'MI(233).jpg',\n",
              " 'MI(234).jpg',\n",
              " 'MI(235).jpg',\n",
              " 'MI(236).jpg',\n",
              " 'MI(237).jpg',\n",
              " 'MI(238).jpg',\n",
              " 'MI(239).jpg',\n",
              " 'MI(24).jpg',\n",
              " 'MI(240).jpg',\n",
              " 'MI(25).jpg',\n",
              " 'MI(26).jpg',\n",
              " 'MI(27).jpg',\n",
              " 'MI(28).jpg',\n",
              " 'MI(29).jpg',\n",
              " 'MI(3).jpg',\n",
              " 'MI(30).jpg',\n",
              " 'MI(31).jpg',\n",
              " 'MI(32).jpg',\n",
              " 'MI(33).jpg',\n",
              " 'MI(34).jpg',\n",
              " 'MI(35).jpg',\n",
              " 'MI(36).jpg',\n",
              " 'MI(37).jpg',\n",
              " 'MI(38).jpg',\n",
              " 'MI(39).jpg',\n",
              " 'MI(4).jpg',\n",
              " 'MI(40).jpg',\n",
              " 'MI(41).jpg',\n",
              " 'MI(42).jpg',\n",
              " 'MI(43).jpg',\n",
              " 'MI(44).jpg',\n",
              " 'MI(45).jpg',\n",
              " 'MI(46).jpg',\n",
              " 'MI(47).jpg',\n",
              " 'MI(48).jpg',\n",
              " 'MI(49).jpg',\n",
              " 'MI(5).jpg',\n",
              " 'MI(50).jpg',\n",
              " 'MI(51).jpg',\n",
              " 'MI(52).jpg',\n",
              " 'MI(53).jpg',\n",
              " 'MI(54).jpg',\n",
              " 'MI(55).jpg',\n",
              " 'MI(56).jpg',\n",
              " 'MI(57).jpg',\n",
              " 'MI(58).jpg',\n",
              " 'MI(59).jpg',\n",
              " 'MI(6).jpg',\n",
              " 'MI(60).jpg',\n",
              " 'MI(61).jpg',\n",
              " 'MI(62).jpg',\n",
              " 'MI(63).jpg',\n",
              " 'MI(64).jpg',\n",
              " 'MI(65).jpg',\n",
              " 'MI(66).jpg',\n",
              " 'MI(67).jpg',\n",
              " 'MI(68).jpg',\n",
              " 'MI(69).jpg',\n",
              " 'MI(7).jpg',\n",
              " 'MI(70).jpg',\n",
              " 'MI(71).jpg',\n",
              " 'MI(72).jpg',\n",
              " 'MI(73).jpg',\n",
              " 'MI(74).jpg',\n",
              " 'MI(75).jpg',\n",
              " 'MI(76).jpg',\n",
              " 'MI(77).jpg',\n",
              " 'MI(78).jpg',\n",
              " 'MI(79).jpg',\n",
              " 'MI(8).jpg',\n",
              " 'MI(80).jpg',\n",
              " 'MI(81).jpg',\n",
              " 'MI(82).jpg',\n",
              " 'MI(83).jpg',\n",
              " 'MI(84).jpg',\n",
              " 'MI(85).jpg',\n",
              " 'MI(86).jpg',\n",
              " 'MI(87).jpg',\n",
              " 'MI(88).jpg',\n",
              " 'MI(89).jpg',\n",
              " 'MI(9).jpg',\n",
              " 'MI(90).jpg',\n",
              " 'MI(91).jpg',\n",
              " 'MI(92).jpg',\n",
              " 'MI(93).jpg',\n",
              " 'MI(94).jpg',\n",
              " 'MI(95).jpg',\n",
              " 'MI(96).jpg',\n",
              " 'MI(97).jpg',\n",
              " 'MI(98).jpg',\n",
              " 'MI(99).jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4LMfTU3UuCM",
        "outputId": "ec33988b-42d6-4d82-db80-39bccabe99ce"
      },
      "source": [
        "PMI_.sort()\n",
        "PMI_"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PMI(1).jpg',\n",
              " 'PMI(10).jpg',\n",
              " 'PMI(100).jpg',\n",
              " 'PMI(101).jpg',\n",
              " 'PMI(102).jpg',\n",
              " 'PMI(103).jpg',\n",
              " 'PMI(104).jpg',\n",
              " 'PMI(105).jpg',\n",
              " 'PMI(106).jpg',\n",
              " 'PMI(107).jpg',\n",
              " 'PMI(108).jpg',\n",
              " 'PMI(109).jpg',\n",
              " 'PMI(11).jpg',\n",
              " 'PMI(110).jpg',\n",
              " 'PMI(111).jpg',\n",
              " 'PMI(112).jpg',\n",
              " 'PMI(113).jpg',\n",
              " 'PMI(114).jpg',\n",
              " 'PMI(115).jpg',\n",
              " 'PMI(116).jpg',\n",
              " 'PMI(117).jpg',\n",
              " 'PMI(118).jpg',\n",
              " 'PMI(119).jpg',\n",
              " 'PMI(12).jpg',\n",
              " 'PMI(120).jpg',\n",
              " 'PMI(121).jpg',\n",
              " 'PMI(122).jpg',\n",
              " 'PMI(123).jpg',\n",
              " 'PMI(124).jpg',\n",
              " 'PMI(125).jpg',\n",
              " 'PMI(126).jpg',\n",
              " 'PMI(127).jpg',\n",
              " 'PMI(128).jpg',\n",
              " 'PMI(129).jpg',\n",
              " 'PMI(13).jpg',\n",
              " 'PMI(130).jpg',\n",
              " 'PMI(131).jpg',\n",
              " 'PMI(132).jpg',\n",
              " 'PMI(133).jpg',\n",
              " 'PMI(134).jpg',\n",
              " 'PMI(135).jpg',\n",
              " 'PMI(136).jpg',\n",
              " 'PMI(137).jpg',\n",
              " 'PMI(138).jpg',\n",
              " 'PMI(139).jpg',\n",
              " 'PMI(14).jpg',\n",
              " 'PMI(140).jpg',\n",
              " 'PMI(141).jpg',\n",
              " 'PMI(142).jpg',\n",
              " 'PMI(143).jpg',\n",
              " 'PMI(144).jpg',\n",
              " 'PMI(145).jpg',\n",
              " 'PMI(146).jpg',\n",
              " 'PMI(147).jpg',\n",
              " 'PMI(148).jpg',\n",
              " 'PMI(149).jpg',\n",
              " 'PMI(15).jpg',\n",
              " 'PMI(150).jpg',\n",
              " 'PMI(151).jpg',\n",
              " 'PMI(152).jpg',\n",
              " 'PMI(153).jpg',\n",
              " 'PMI(154).jpg',\n",
              " 'PMI(155).jpg',\n",
              " 'PMI(156).jpg',\n",
              " 'PMI(157).jpg',\n",
              " 'PMI(158).jpg',\n",
              " 'PMI(159).jpg',\n",
              " 'PMI(16).jpg',\n",
              " 'PMI(160).jpg',\n",
              " 'PMI(161).jpg',\n",
              " 'PMI(162).jpg',\n",
              " 'PMI(163).jpg',\n",
              " 'PMI(164).jpg',\n",
              " 'PMI(165).jpg',\n",
              " 'PMI(166).jpg',\n",
              " 'PMI(167).jpg',\n",
              " 'PMI(168).jpg',\n",
              " 'PMI(169).jpg',\n",
              " 'PMI(17).jpg',\n",
              " 'PMI(170).jpg',\n",
              " 'PMI(171).jpg',\n",
              " 'PMI(172).jpg',\n",
              " 'PMI(18).jpg',\n",
              " 'PMI(19).jpg',\n",
              " 'PMI(2).jpg',\n",
              " 'PMI(20).jpg',\n",
              " 'PMI(21).jpg',\n",
              " 'PMI(22).jpg',\n",
              " 'PMI(23).jpg',\n",
              " 'PMI(24).jpg',\n",
              " 'PMI(25).jpg',\n",
              " 'PMI(26).jpg',\n",
              " 'PMI(27).jpg',\n",
              " 'PMI(28).jpg',\n",
              " 'PMI(29).jpg',\n",
              " 'PMI(3).jpg',\n",
              " 'PMI(30).jpg',\n",
              " 'PMI(31).jpg',\n",
              " 'PMI(32).jpg',\n",
              " 'PMI(33).jpg',\n",
              " 'PMI(34).jpg',\n",
              " 'PMI(35).jpg',\n",
              " 'PMI(36).jpg',\n",
              " 'PMI(37).jpg',\n",
              " 'PMI(38).jpg',\n",
              " 'PMI(39).jpg',\n",
              " 'PMI(4).jpg',\n",
              " 'PMI(40).jpg',\n",
              " 'PMI(41).jpg',\n",
              " 'PMI(42).jpg',\n",
              " 'PMI(43).jpg',\n",
              " 'PMI(44).jpg',\n",
              " 'PMI(45).jpg',\n",
              " 'PMI(46).jpg',\n",
              " 'PMI(47).jpg',\n",
              " 'PMI(48).jpg',\n",
              " 'PMI(49).jpg',\n",
              " 'PMI(5).jpg',\n",
              " 'PMI(50).jpg',\n",
              " 'PMI(51).jpg',\n",
              " 'PMI(52).jpg',\n",
              " 'PMI(53).jpg',\n",
              " 'PMI(54).jpg',\n",
              " 'PMI(55).jpg',\n",
              " 'PMI(56).jpg',\n",
              " 'PMI(57).jpg',\n",
              " 'PMI(58).jpg',\n",
              " 'PMI(59).jpg',\n",
              " 'PMI(6).jpg',\n",
              " 'PMI(60).jpg',\n",
              " 'PMI(61).jpg',\n",
              " 'PMI(62).jpg',\n",
              " 'PMI(63).jpg',\n",
              " 'PMI(64).jpg',\n",
              " 'PMI(65).jpg',\n",
              " 'PMI(66).jpg',\n",
              " 'PMI(67).jpg',\n",
              " 'PMI(68).jpg',\n",
              " 'PMI(69).jpg',\n",
              " 'PMI(7).jpg',\n",
              " 'PMI(70).jpg',\n",
              " 'PMI(71).jpg',\n",
              " 'PMI(72).jpg',\n",
              " 'PMI(73).jpg',\n",
              " 'PMI(74).jpg',\n",
              " 'PMI(75).jpg',\n",
              " 'PMI(76).jpg',\n",
              " 'PMI(77).jpg',\n",
              " 'PMI(78).jpg',\n",
              " 'PMI(79).jpg',\n",
              " 'PMI(8).jpg',\n",
              " 'PMI(80).jpg',\n",
              " 'PMI(81).jpg',\n",
              " 'PMI(82).jpg',\n",
              " 'PMI(83).jpg',\n",
              " 'PMI(84).jpg',\n",
              " 'PMI(85).jpg',\n",
              " 'PMI(86).jpg',\n",
              " 'PMI(87).jpg',\n",
              " 'PMI(88).jpg',\n",
              " 'PMI(89).jpg',\n",
              " 'PMI(9).jpg',\n",
              " 'PMI(90).jpg',\n",
              " 'PMI(91).jpg',\n",
              " 'PMI(92).jpg',\n",
              " 'PMI(93).jpg',\n",
              " 'PMI(94).jpg',\n",
              " 'PMI(95).jpg',\n",
              " 'PMI(96).jpg',\n",
              " 'PMI(97).jpg',\n",
              " 'PMI(98).jpg',\n",
              " 'PMI(99).jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OinhdMKtU5mf",
        "outputId": "e9357a3a-50c1-4c8f-876a-8eeaa7d008b9"
      },
      "source": [
        "MI_.sort()\n",
        "MI_"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MI(1).jpg',\n",
              " 'MI(10).jpg',\n",
              " 'MI(100).jpg',\n",
              " 'MI(101).jpg',\n",
              " 'MI(102).jpg',\n",
              " 'MI(103).jpg',\n",
              " 'MI(104).jpg',\n",
              " 'MI(105).jpg',\n",
              " 'MI(106).jpg',\n",
              " 'MI(107).jpg',\n",
              " 'MI(108).jpg',\n",
              " 'MI(109).jpg',\n",
              " 'MI(11).jpg',\n",
              " 'MI(110).jpg',\n",
              " 'MI(111).jpg',\n",
              " 'MI(112).jpg',\n",
              " 'MI(113).jpg',\n",
              " 'MI(114).jpg',\n",
              " 'MI(115).jpg',\n",
              " 'MI(116).jpg',\n",
              " 'MI(117).jpg',\n",
              " 'MI(118).jpg',\n",
              " 'MI(119).jpg',\n",
              " 'MI(12).jpg',\n",
              " 'MI(120).jpg',\n",
              " 'MI(121).jpg',\n",
              " 'MI(122).jpg',\n",
              " 'MI(123).jpg',\n",
              " 'MI(124).jpg',\n",
              " 'MI(125).jpg',\n",
              " 'MI(126).jpg',\n",
              " 'MI(127).jpg',\n",
              " 'MI(128).jpg',\n",
              " 'MI(129).jpg',\n",
              " 'MI(13).jpg',\n",
              " 'MI(130).jpg',\n",
              " 'MI(131).jpg',\n",
              " 'MI(132).jpg',\n",
              " 'MI(133).jpg',\n",
              " 'MI(134).jpg',\n",
              " 'MI(135).jpg',\n",
              " 'MI(136).jpg',\n",
              " 'MI(137).jpg',\n",
              " 'MI(138).jpg',\n",
              " 'MI(139).jpg',\n",
              " 'MI(14).jpg',\n",
              " 'MI(140).jpg',\n",
              " 'MI(141).jpg',\n",
              " 'MI(142).jpg',\n",
              " 'MI(143).jpg',\n",
              " 'MI(144).jpg',\n",
              " 'MI(145).jpg',\n",
              " 'MI(146).jpg',\n",
              " 'MI(147).jpg',\n",
              " 'MI(148).jpg',\n",
              " 'MI(149).jpg',\n",
              " 'MI(15).jpg',\n",
              " 'MI(150).jpg',\n",
              " 'MI(151).jpg',\n",
              " 'MI(152).jpg',\n",
              " 'MI(153).jpg',\n",
              " 'MI(154).jpg',\n",
              " 'MI(155).jpg',\n",
              " 'MI(156).jpg',\n",
              " 'MI(157).jpg',\n",
              " 'MI(158).jpg',\n",
              " 'MI(159).jpg',\n",
              " 'MI(16).jpg',\n",
              " 'MI(160).jpg',\n",
              " 'MI(161).jpg',\n",
              " 'MI(162).jpg',\n",
              " 'MI(163).jpg',\n",
              " 'MI(164).jpg',\n",
              " 'MI(165).jpg',\n",
              " 'MI(166).jpg',\n",
              " 'MI(167).jpg',\n",
              " 'MI(168).jpg',\n",
              " 'MI(169).jpg',\n",
              " 'MI(17).jpg',\n",
              " 'MI(170).jpg',\n",
              " 'MI(171).jpg',\n",
              " 'MI(172).jpg',\n",
              " 'MI(173).jpg',\n",
              " 'MI(174).jpg',\n",
              " 'MI(175).jpg',\n",
              " 'MI(176).jpg',\n",
              " 'MI(177).jpg',\n",
              " 'MI(178).jpg',\n",
              " 'MI(179).jpg',\n",
              " 'MI(18).jpg',\n",
              " 'MI(180).jpg',\n",
              " 'MI(181).jpg',\n",
              " 'MI(182).jpg',\n",
              " 'MI(183).jpg',\n",
              " 'MI(184).jpg',\n",
              " 'MI(185).jpg',\n",
              " 'MI(186).jpg',\n",
              " 'MI(187).jpg',\n",
              " 'MI(188).jpg',\n",
              " 'MI(189).jpg',\n",
              " 'MI(19).jpg',\n",
              " 'MI(190).jpg',\n",
              " 'MI(191).jpg',\n",
              " 'MI(192).jpg',\n",
              " 'MI(193).jpg',\n",
              " 'MI(194).jpg',\n",
              " 'MI(195).jpg',\n",
              " 'MI(196).jpg',\n",
              " 'MI(197).jpg',\n",
              " 'MI(198).jpg',\n",
              " 'MI(199).jpg',\n",
              " 'MI(2).jpg',\n",
              " 'MI(20).jpg',\n",
              " 'MI(200).jpg',\n",
              " 'MI(201).jpg',\n",
              " 'MI(202).jpg',\n",
              " 'MI(203).jpg',\n",
              " 'MI(204).jpg',\n",
              " 'MI(205).jpg',\n",
              " 'MI(206).jpg',\n",
              " 'MI(207).jpg',\n",
              " 'MI(208).jpg',\n",
              " 'MI(209).jpg',\n",
              " 'MI(21).jpg',\n",
              " 'MI(210).jpg',\n",
              " 'MI(211).jpg',\n",
              " 'MI(212).jpg',\n",
              " 'MI(213).jpg',\n",
              " 'MI(214).jpg',\n",
              " 'MI(216).jpg',\n",
              " 'MI(217).jpg',\n",
              " 'MI(218).jpg',\n",
              " 'MI(219).jpg',\n",
              " 'MI(22).jpg',\n",
              " 'MI(220).jpg',\n",
              " 'MI(221).jpg',\n",
              " 'MI(222).jpg',\n",
              " 'MI(223).jpg',\n",
              " 'MI(224).jpg',\n",
              " 'MI(225).jpg',\n",
              " 'MI(226).jpg',\n",
              " 'MI(227).jpg',\n",
              " 'MI(228).jpg',\n",
              " 'MI(229).jpg',\n",
              " 'MI(23).jpg',\n",
              " 'MI(230).jpg',\n",
              " 'MI(231).jpg',\n",
              " 'MI(232).jpg',\n",
              " 'MI(233).jpg',\n",
              " 'MI(234).jpg',\n",
              " 'MI(235).jpg',\n",
              " 'MI(236).jpg',\n",
              " 'MI(237).jpg',\n",
              " 'MI(238).jpg',\n",
              " 'MI(239).jpg',\n",
              " 'MI(24).jpg',\n",
              " 'MI(240).jpg',\n",
              " 'MI(25).jpg',\n",
              " 'MI(26).jpg',\n",
              " 'MI(27).jpg',\n",
              " 'MI(28).jpg',\n",
              " 'MI(29).jpg',\n",
              " 'MI(3).jpg',\n",
              " 'MI(30).jpg',\n",
              " 'MI(31).jpg',\n",
              " 'MI(32).jpg',\n",
              " 'MI(33).jpg',\n",
              " 'MI(34).jpg',\n",
              " 'MI(35).jpg',\n",
              " 'MI(36).jpg',\n",
              " 'MI(37).jpg',\n",
              " 'MI(38).jpg',\n",
              " 'MI(39).jpg',\n",
              " 'MI(4).jpg',\n",
              " 'MI(40).jpg',\n",
              " 'MI(41).jpg',\n",
              " 'MI(42).jpg',\n",
              " 'MI(43).jpg',\n",
              " 'MI(44).jpg',\n",
              " 'MI(45).jpg',\n",
              " 'MI(46).jpg',\n",
              " 'MI(47).jpg',\n",
              " 'MI(48).jpg',\n",
              " 'MI(49).jpg',\n",
              " 'MI(5).jpg',\n",
              " 'MI(50).jpg',\n",
              " 'MI(51).jpg',\n",
              " 'MI(52).jpg',\n",
              " 'MI(53).jpg',\n",
              " 'MI(54).jpg',\n",
              " 'MI(55).jpg',\n",
              " 'MI(56).jpg',\n",
              " 'MI(57).jpg',\n",
              " 'MI(58).jpg',\n",
              " 'MI(59).jpg',\n",
              " 'MI(6).jpg',\n",
              " 'MI(60).jpg',\n",
              " 'MI(61).jpg',\n",
              " 'MI(62).jpg',\n",
              " 'MI(63).jpg',\n",
              " 'MI(64).jpg',\n",
              " 'MI(65).jpg',\n",
              " 'MI(66).jpg',\n",
              " 'MI(67).jpg',\n",
              " 'MI(68).jpg',\n",
              " 'MI(69).jpg',\n",
              " 'MI(7).jpg',\n",
              " 'MI(70).jpg',\n",
              " 'MI(71).jpg',\n",
              " 'MI(72).jpg',\n",
              " 'MI(73).jpg',\n",
              " 'MI(74).jpg',\n",
              " 'MI(75).jpg',\n",
              " 'MI(76).jpg',\n",
              " 'MI(77).jpg',\n",
              " 'MI(78).jpg',\n",
              " 'MI(79).jpg',\n",
              " 'MI(8).jpg',\n",
              " 'MI(80).jpg',\n",
              " 'MI(81).jpg',\n",
              " 'MI(82).jpg',\n",
              " 'MI(83).jpg',\n",
              " 'MI(84).jpg',\n",
              " 'MI(85).jpg',\n",
              " 'MI(86).jpg',\n",
              " 'MI(87).jpg',\n",
              " 'MI(88).jpg',\n",
              " 'MI(89).jpg',\n",
              " 'MI(9).jpg',\n",
              " 'MI(90).jpg',\n",
              " 'MI(91).jpg',\n",
              " 'MI(92).jpg',\n",
              " 'MI(93).jpg',\n",
              " 'MI(94).jpg',\n",
              " 'MI(95).jpg',\n",
              " 'MI(96).jpg',\n",
              " 'MI(97).jpg',\n",
              " 'MI(98).jpg',\n",
              " 'MI(99).jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T4Ay50ch6Ru"
      },
      "source": [
        "#### **COMBINED CSV OF EACH LEAD(1-12) FROM ALL IMAGES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ot65BTX2VF7Y"
      },
      "source": [
        "#loop over and create combined csv files for each leads.\n",
        "#for x in range(len(MI_)):\n",
        " #df2=pd.read_csv('/AHB')\n",
        "  #df3=pd.read_csv('/MI')\n",
        "  #df4=pd.read_csv('/PM')\n",
        "  #final_df = pd.concat([df1,df2,df3,df4],ignore_index=True)\n",
        "  #final_df.to_csv('/Combined_IDLead_.csv')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQN9hb-CoR33",
        "outputId": "e205ad83-d348-4fe0-fb4d-e216e03210c1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyTYwqJSX8Vh",
        "outputId": "f304cbe6-2f3c-4c0a-91f3-64feb20e6ff6"
      },
      "source": [
        "#now reading just lead1\n",
        "df=pd.read_csv('/Combined_IDLead_.csv/Combined_IDLead_1.csv')\n",
        "df['Target'].unique()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['No', 'HB', 'MI', 'PM'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbSKpUc2angF"
      },
      "source": [
        "df.drop(columns=['Unnamed: 0'],inplace=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "fX_uYtekhL_z",
        "outputId": "2fd784d7-0491-4ec5-aae3-1e20724b2e8a"
      },
      "source": [
        "#convert Target column values as Numeric using ngroups\n",
        "encode_target_label = df.groupby('Target').ngroup().rename(\"target\").to_frame()\n",
        "test_final  = df.merge(encode_target_label, left_index=True, right_index=True)\n",
        "test_final.drop(columns=['Target'],inplace=True)\n",
        "test_final"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6  \\\n",
              "0    0.728449  0.680755  0.619010  0.645367  0.681570  0.732488  0.758448   \n",
              "1    0.957972  0.950695  0.941024  0.930501  0.913601  0.892244  0.868016   \n",
              "2    0.611084  0.661575  0.695790  0.741113  0.716666  0.595794  0.425022   \n",
              "3    0.839213  0.861690  0.866457  0.865756  0.855027  0.855606  0.845561   \n",
              "4    0.917753  0.924369  0.873765  0.791381  0.699513  0.604927  0.500312   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "923  0.874246  0.877014  0.864280  0.860505  0.871349  0.912404  0.958148   \n",
              "924  0.829815  0.832084  0.852396  0.909665  0.988242  1.000000  0.923323   \n",
              "925  0.469048  0.417983  0.362322  0.351995  0.391493  0.418305  0.440135   \n",
              "926  0.682510  0.682286  0.641051  0.620212  0.608210  0.576331  0.603596   \n",
              "927  0.792175  0.815695  0.819518  0.820559  0.847985  0.880933  0.902061   \n",
              "\n",
              "            7         8         9  ...       246       247       248  \\\n",
              "0    0.750660  0.728282  0.707928  ...  0.637260  0.664539  0.667226   \n",
              "1    0.855127  0.835307  0.798640  ...  0.778790  0.806883  0.818640   \n",
              "2    0.286457  0.425022  0.611384  ...  0.000000  0.042690  0.165850   \n",
              "3    0.843187  0.846784  0.824438  ...  0.789156  0.793622  0.787665   \n",
              "4    0.446012  0.528910  0.634068  ...  0.200676  0.300147  0.407225   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "923  0.977826  0.956314  0.926773  ...  0.908312  0.926328  0.898749   \n",
              "924  0.821865  0.721302  0.612039  ...  0.429721  0.531567  0.642137   \n",
              "925  0.444598  0.460402  0.506810  ...  0.408587  0.401864  0.387069   \n",
              "926  0.645714  0.677964  0.720297  ...  0.452247  0.450421  0.439278   \n",
              "927  0.878266  0.838806  0.811795  ...  0.737351  0.778845  0.805446   \n",
              "\n",
              "          249       250       251       252       253       254  target  \n",
              "0    0.637064  0.593287  0.545503  0.515049  0.563257  0.633581       2  \n",
              "1    0.842472  0.866740  0.884152  0.897196  0.911293  0.922903       2  \n",
              "2    0.363445  0.549460  0.539346  0.522272  0.491668  0.454949       2  \n",
              "3    0.794515  0.796739  0.804063  0.809944  0.801814  0.777322       2  \n",
              "4    0.507346  0.605953  0.699309  0.790334  0.856593  0.849957       2  \n",
              "..        ...       ...       ...       ...       ...       ...     ...  \n",
              "923  0.855709  0.823132  0.815458  0.818083  0.829300  0.822382       3  \n",
              "924  0.742063  0.833042  0.814867  0.777622  0.760714  0.759294       3  \n",
              "925  0.359590  0.325879  0.288894  0.293521  0.344504  0.399012       3  \n",
              "926  0.439086  0.394417  0.441650  0.473909  0.539199  0.547146       3  \n",
              "927  0.782640  0.751236  0.741331  0.718790  0.714504  0.691004       3  \n",
              "\n",
              "[928 rows x 256 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de9d07a7-fb63-40bf-8295-dd60f8bbdb9d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>246</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.728449</td>\n",
              "      <td>0.680755</td>\n",
              "      <td>0.619010</td>\n",
              "      <td>0.645367</td>\n",
              "      <td>0.681570</td>\n",
              "      <td>0.732488</td>\n",
              "      <td>0.758448</td>\n",
              "      <td>0.750660</td>\n",
              "      <td>0.728282</td>\n",
              "      <td>0.707928</td>\n",
              "      <td>...</td>\n",
              "      <td>0.637260</td>\n",
              "      <td>0.664539</td>\n",
              "      <td>0.667226</td>\n",
              "      <td>0.637064</td>\n",
              "      <td>0.593287</td>\n",
              "      <td>0.545503</td>\n",
              "      <td>0.515049</td>\n",
              "      <td>0.563257</td>\n",
              "      <td>0.633581</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.957972</td>\n",
              "      <td>0.950695</td>\n",
              "      <td>0.941024</td>\n",
              "      <td>0.930501</td>\n",
              "      <td>0.913601</td>\n",
              "      <td>0.892244</td>\n",
              "      <td>0.868016</td>\n",
              "      <td>0.855127</td>\n",
              "      <td>0.835307</td>\n",
              "      <td>0.798640</td>\n",
              "      <td>...</td>\n",
              "      <td>0.778790</td>\n",
              "      <td>0.806883</td>\n",
              "      <td>0.818640</td>\n",
              "      <td>0.842472</td>\n",
              "      <td>0.866740</td>\n",
              "      <td>0.884152</td>\n",
              "      <td>0.897196</td>\n",
              "      <td>0.911293</td>\n",
              "      <td>0.922903</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.611084</td>\n",
              "      <td>0.661575</td>\n",
              "      <td>0.695790</td>\n",
              "      <td>0.741113</td>\n",
              "      <td>0.716666</td>\n",
              "      <td>0.595794</td>\n",
              "      <td>0.425022</td>\n",
              "      <td>0.286457</td>\n",
              "      <td>0.425022</td>\n",
              "      <td>0.611384</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.042690</td>\n",
              "      <td>0.165850</td>\n",
              "      <td>0.363445</td>\n",
              "      <td>0.549460</td>\n",
              "      <td>0.539346</td>\n",
              "      <td>0.522272</td>\n",
              "      <td>0.491668</td>\n",
              "      <td>0.454949</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.839213</td>\n",
              "      <td>0.861690</td>\n",
              "      <td>0.866457</td>\n",
              "      <td>0.865756</td>\n",
              "      <td>0.855027</td>\n",
              "      <td>0.855606</td>\n",
              "      <td>0.845561</td>\n",
              "      <td>0.843187</td>\n",
              "      <td>0.846784</td>\n",
              "      <td>0.824438</td>\n",
              "      <td>...</td>\n",
              "      <td>0.789156</td>\n",
              "      <td>0.793622</td>\n",
              "      <td>0.787665</td>\n",
              "      <td>0.794515</td>\n",
              "      <td>0.796739</td>\n",
              "      <td>0.804063</td>\n",
              "      <td>0.809944</td>\n",
              "      <td>0.801814</td>\n",
              "      <td>0.777322</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.917753</td>\n",
              "      <td>0.924369</td>\n",
              "      <td>0.873765</td>\n",
              "      <td>0.791381</td>\n",
              "      <td>0.699513</td>\n",
              "      <td>0.604927</td>\n",
              "      <td>0.500312</td>\n",
              "      <td>0.446012</td>\n",
              "      <td>0.528910</td>\n",
              "      <td>0.634068</td>\n",
              "      <td>...</td>\n",
              "      <td>0.200676</td>\n",
              "      <td>0.300147</td>\n",
              "      <td>0.407225</td>\n",
              "      <td>0.507346</td>\n",
              "      <td>0.605953</td>\n",
              "      <td>0.699309</td>\n",
              "      <td>0.790334</td>\n",
              "      <td>0.856593</td>\n",
              "      <td>0.849957</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>923</th>\n",
              "      <td>0.874246</td>\n",
              "      <td>0.877014</td>\n",
              "      <td>0.864280</td>\n",
              "      <td>0.860505</td>\n",
              "      <td>0.871349</td>\n",
              "      <td>0.912404</td>\n",
              "      <td>0.958148</td>\n",
              "      <td>0.977826</td>\n",
              "      <td>0.956314</td>\n",
              "      <td>0.926773</td>\n",
              "      <td>...</td>\n",
              "      <td>0.908312</td>\n",
              "      <td>0.926328</td>\n",
              "      <td>0.898749</td>\n",
              "      <td>0.855709</td>\n",
              "      <td>0.823132</td>\n",
              "      <td>0.815458</td>\n",
              "      <td>0.818083</td>\n",
              "      <td>0.829300</td>\n",
              "      <td>0.822382</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>924</th>\n",
              "      <td>0.829815</td>\n",
              "      <td>0.832084</td>\n",
              "      <td>0.852396</td>\n",
              "      <td>0.909665</td>\n",
              "      <td>0.988242</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.923323</td>\n",
              "      <td>0.821865</td>\n",
              "      <td>0.721302</td>\n",
              "      <td>0.612039</td>\n",
              "      <td>...</td>\n",
              "      <td>0.429721</td>\n",
              "      <td>0.531567</td>\n",
              "      <td>0.642137</td>\n",
              "      <td>0.742063</td>\n",
              "      <td>0.833042</td>\n",
              "      <td>0.814867</td>\n",
              "      <td>0.777622</td>\n",
              "      <td>0.760714</td>\n",
              "      <td>0.759294</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>925</th>\n",
              "      <td>0.469048</td>\n",
              "      <td>0.417983</td>\n",
              "      <td>0.362322</td>\n",
              "      <td>0.351995</td>\n",
              "      <td>0.391493</td>\n",
              "      <td>0.418305</td>\n",
              "      <td>0.440135</td>\n",
              "      <td>0.444598</td>\n",
              "      <td>0.460402</td>\n",
              "      <td>0.506810</td>\n",
              "      <td>...</td>\n",
              "      <td>0.408587</td>\n",
              "      <td>0.401864</td>\n",
              "      <td>0.387069</td>\n",
              "      <td>0.359590</td>\n",
              "      <td>0.325879</td>\n",
              "      <td>0.288894</td>\n",
              "      <td>0.293521</td>\n",
              "      <td>0.344504</td>\n",
              "      <td>0.399012</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>926</th>\n",
              "      <td>0.682510</td>\n",
              "      <td>0.682286</td>\n",
              "      <td>0.641051</td>\n",
              "      <td>0.620212</td>\n",
              "      <td>0.608210</td>\n",
              "      <td>0.576331</td>\n",
              "      <td>0.603596</td>\n",
              "      <td>0.645714</td>\n",
              "      <td>0.677964</td>\n",
              "      <td>0.720297</td>\n",
              "      <td>...</td>\n",
              "      <td>0.452247</td>\n",
              "      <td>0.450421</td>\n",
              "      <td>0.439278</td>\n",
              "      <td>0.439086</td>\n",
              "      <td>0.394417</td>\n",
              "      <td>0.441650</td>\n",
              "      <td>0.473909</td>\n",
              "      <td>0.539199</td>\n",
              "      <td>0.547146</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>927</th>\n",
              "      <td>0.792175</td>\n",
              "      <td>0.815695</td>\n",
              "      <td>0.819518</td>\n",
              "      <td>0.820559</td>\n",
              "      <td>0.847985</td>\n",
              "      <td>0.880933</td>\n",
              "      <td>0.902061</td>\n",
              "      <td>0.878266</td>\n",
              "      <td>0.838806</td>\n",
              "      <td>0.811795</td>\n",
              "      <td>...</td>\n",
              "      <td>0.737351</td>\n",
              "      <td>0.778845</td>\n",
              "      <td>0.805446</td>\n",
              "      <td>0.782640</td>\n",
              "      <td>0.751236</td>\n",
              "      <td>0.741331</td>\n",
              "      <td>0.718790</td>\n",
              "      <td>0.714504</td>\n",
              "      <td>0.691004</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>928 rows × 256 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de9d07a7-fb63-40bf-8295-dd60f8bbdb9d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-de9d07a7-fb63-40bf-8295-dd60f8bbdb9d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-de9d07a7-fb63-40bf-8295-dd60f8bbdb9d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRvRDvfrivtE"
      },
      "source": [
        "#### **PERFORM DIMENSIONALITY REDUCTION JUST FOR CHECKING/UNDERSTANDING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 956
        },
        "id": "scVPRQ3TZBaW",
        "outputId": "eb7f70fd-b471-496a-8e60-a8fb51565f40"
      },
      "source": [
        "#just for testing\n",
        "# Now Perform Dimensionality reduction (PCA) on that Dataframe and check\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#do PCA and choose componeents as 100\n",
        "pca = PCA(n_components=100)\n",
        "x_pca = pca.fit_transform(test_final.iloc[:,0:-1])\n",
        "x_pca = pd.DataFrame(x_pca)\n",
        "\n",
        "# Calculate the variance explained by priciple components\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "print('Variance of each component:', pca.explained_variance_ratio_)\n",
        "print('\\n Total Variance Explained:', round(sum(list(pca.explained_variance_ratio_))*100, 2))\n",
        "\n",
        "#store the new pca generated dimensions in a dataframe\n",
        "pca_df = pd.DataFrame(data = x_pca)\n",
        "target = pd.Series(test_final['target'], name='target')\n",
        "result_df = pd.concat([pca_df, target], axis=1)\n",
        "result_df"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variance of each component: [1.76145888e-01 9.50265614e-02 6.99060614e-02 6.15960001e-02\n",
            " 5.34876630e-02 4.23664893e-02 3.68320213e-02 3.38541791e-02\n",
            " 3.00884979e-02 2.90396728e-02 2.64962509e-02 2.42272738e-02\n",
            " 2.10221030e-02 1.99751559e-02 1.77321042e-02 1.63016802e-02\n",
            " 1.53898622e-02 1.48412074e-02 1.33644825e-02 1.19674074e-02\n",
            " 1.16813409e-02 1.05807650e-02 9.68875480e-03 9.47385060e-03\n",
            " 8.65347748e-03 8.47506998e-03 7.93382172e-03 7.30163338e-03\n",
            " 6.76380665e-03 6.36886390e-03 6.02004791e-03 5.46823032e-03\n",
            " 5.31229911e-03 4.97821789e-03 4.74686092e-03 4.46081684e-03\n",
            " 4.21254684e-03 4.01200243e-03 3.87246476e-03 3.52519084e-03\n",
            " 3.37596894e-03 3.26978336e-03 3.08241145e-03 2.96423495e-03\n",
            " 2.73419816e-03 2.50965698e-03 2.35335480e-03 2.25665349e-03\n",
            " 2.20141761e-03 1.96782025e-03 1.74343954e-03 1.70982830e-03\n",
            " 1.57456047e-03 1.53704487e-03 1.36768435e-03 1.33167096e-03\n",
            " 1.26444173e-03 1.20053330e-03 1.18738749e-03 1.08864087e-03\n",
            " 1.02824532e-03 9.11484783e-04 7.89962329e-04 7.59785111e-04\n",
            " 6.49920864e-04 6.27833793e-04 6.04784065e-04 5.45886708e-04\n",
            " 5.32310104e-04 4.97728349e-04 4.78393196e-04 4.50404967e-04\n",
            " 4.26173489e-04 4.09392346e-04 3.92601463e-04 3.70241593e-04\n",
            " 3.66854847e-04 3.38846625e-04 3.08205842e-04 3.00634008e-04\n",
            " 2.80363492e-04 2.67851040e-04 2.49660867e-04 2.40638061e-04\n",
            " 2.11563629e-04 2.03939408e-04 1.99024451e-04 1.83141333e-04\n",
            " 1.66812220e-04 1.65872575e-04 1.55971493e-04 1.39169214e-04\n",
            " 1.25297630e-04 1.22288293e-04 1.13464623e-04 1.09363639e-04\n",
            " 1.03173185e-04 9.93769322e-05 9.86275005e-05 9.44740363e-05]\n",
            "\n",
            " Total Variance Explained: 99.8\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6  \\\n",
              "0    1.018578  1.148263 -0.589582  0.193617  0.047950 -0.309400 -0.161566   \n",
              "1   -1.098692  0.289832 -1.766388  1.076165 -0.261201 -0.820446 -0.474188   \n",
              "2    0.275021 -0.451289  0.106750 -0.426415  0.066133  0.692474  0.634894   \n",
              "3   -1.517085  1.662693 -1.021167  0.804267 -0.281985  0.518180  0.355748   \n",
              "4   -0.152840 -1.046283  0.351278  1.100381 -1.613642  1.484188 -0.113277   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "923 -1.321884  2.153021  0.788596 -1.304253  0.458186 -0.859346 -0.069127   \n",
              "924 -0.867163 -0.040504  0.940680  0.302648 -0.469672 -0.368255  1.065579   \n",
              "925  3.753012  0.841636 -0.317393 -0.296117  0.593769 -0.255474 -0.057091   \n",
              "926  0.603083  0.126259  0.003433  0.283612  0.169559 -0.156326 -0.068399   \n",
              "927 -1.452945  1.233599  0.439472  0.278517  0.165928 -0.171830 -0.075000   \n",
              "\n",
              "            7         8         9  ...        91        92        93  \\\n",
              "0    0.478471  0.972403 -0.031832  ...  0.011401 -0.005266  0.024463   \n",
              "1   -0.515238  0.692389  1.501606  ... -0.017395  0.061048 -0.006449   \n",
              "2   -0.035867  0.815855 -0.909473  ...  0.044931 -0.041293 -0.029850   \n",
              "3   -0.344235 -0.910867 -0.629517  ...  0.000813  0.041376  0.017896   \n",
              "4   -0.251152  0.179023 -0.233104  ... -0.009842  0.054811  0.003233   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "923 -0.392796  0.755732 -0.584050  ... -0.037611  0.078257 -0.043549   \n",
              "924  0.801522  0.690113  0.953008  ...  0.012459 -0.094131  0.012074   \n",
              "925 -0.072048  0.664386 -0.837668  ... -0.008577 -0.005870 -0.003372   \n",
              "926 -0.184308  0.461063 -0.002047  ...  0.056610  0.024137 -0.014507   \n",
              "927  0.033859  0.004444 -0.687583  ...  0.012713 -0.031891  0.069221   \n",
              "\n",
              "           94        95        96        97        98        99  target  \n",
              "0    0.013750 -0.000566  0.003781  0.008153 -0.062281 -0.027277       2  \n",
              "1    0.011315  0.002456  0.046974  0.033646 -0.033041  0.000557       2  \n",
              "2    0.123353 -0.052389 -0.014348 -0.022480  0.050400  0.009272       2  \n",
              "3   -0.054519 -0.037309 -0.017877 -0.022058  0.023475 -0.037341       2  \n",
              "4    0.031708  0.015571 -0.004691  0.043818  0.003463 -0.027180       2  \n",
              "..        ...       ...       ...       ...       ...       ...     ...  \n",
              "923 -0.030543  0.008307 -0.027181 -0.049055 -0.010741  0.011886       3  \n",
              "924 -0.028681 -0.007974  0.061485 -0.007939 -0.062855 -0.020197       3  \n",
              "925  0.003218 -0.019323  0.066904  0.021464 -0.001711 -0.011906       3  \n",
              "926 -0.081209 -0.000572  0.030829 -0.056736  0.021194  0.066228       3  \n",
              "927 -0.062677  0.013343 -0.074262  0.005516 -0.055673 -0.029486       3  \n",
              "\n",
              "[928 rows x 101 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25a3e7c4-17ce-4ff6-a78d-c68e995fe066\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.018578</td>\n",
              "      <td>1.148263</td>\n",
              "      <td>-0.589582</td>\n",
              "      <td>0.193617</td>\n",
              "      <td>0.047950</td>\n",
              "      <td>-0.309400</td>\n",
              "      <td>-0.161566</td>\n",
              "      <td>0.478471</td>\n",
              "      <td>0.972403</td>\n",
              "      <td>-0.031832</td>\n",
              "      <td>...</td>\n",
              "      <td>0.011401</td>\n",
              "      <td>-0.005266</td>\n",
              "      <td>0.024463</td>\n",
              "      <td>0.013750</td>\n",
              "      <td>-0.000566</td>\n",
              "      <td>0.003781</td>\n",
              "      <td>0.008153</td>\n",
              "      <td>-0.062281</td>\n",
              "      <td>-0.027277</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.098692</td>\n",
              "      <td>0.289832</td>\n",
              "      <td>-1.766388</td>\n",
              "      <td>1.076165</td>\n",
              "      <td>-0.261201</td>\n",
              "      <td>-0.820446</td>\n",
              "      <td>-0.474188</td>\n",
              "      <td>-0.515238</td>\n",
              "      <td>0.692389</td>\n",
              "      <td>1.501606</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.017395</td>\n",
              "      <td>0.061048</td>\n",
              "      <td>-0.006449</td>\n",
              "      <td>0.011315</td>\n",
              "      <td>0.002456</td>\n",
              "      <td>0.046974</td>\n",
              "      <td>0.033646</td>\n",
              "      <td>-0.033041</td>\n",
              "      <td>0.000557</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.275021</td>\n",
              "      <td>-0.451289</td>\n",
              "      <td>0.106750</td>\n",
              "      <td>-0.426415</td>\n",
              "      <td>0.066133</td>\n",
              "      <td>0.692474</td>\n",
              "      <td>0.634894</td>\n",
              "      <td>-0.035867</td>\n",
              "      <td>0.815855</td>\n",
              "      <td>-0.909473</td>\n",
              "      <td>...</td>\n",
              "      <td>0.044931</td>\n",
              "      <td>-0.041293</td>\n",
              "      <td>-0.029850</td>\n",
              "      <td>0.123353</td>\n",
              "      <td>-0.052389</td>\n",
              "      <td>-0.014348</td>\n",
              "      <td>-0.022480</td>\n",
              "      <td>0.050400</td>\n",
              "      <td>0.009272</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.517085</td>\n",
              "      <td>1.662693</td>\n",
              "      <td>-1.021167</td>\n",
              "      <td>0.804267</td>\n",
              "      <td>-0.281985</td>\n",
              "      <td>0.518180</td>\n",
              "      <td>0.355748</td>\n",
              "      <td>-0.344235</td>\n",
              "      <td>-0.910867</td>\n",
              "      <td>-0.629517</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000813</td>\n",
              "      <td>0.041376</td>\n",
              "      <td>0.017896</td>\n",
              "      <td>-0.054519</td>\n",
              "      <td>-0.037309</td>\n",
              "      <td>-0.017877</td>\n",
              "      <td>-0.022058</td>\n",
              "      <td>0.023475</td>\n",
              "      <td>-0.037341</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.152840</td>\n",
              "      <td>-1.046283</td>\n",
              "      <td>0.351278</td>\n",
              "      <td>1.100381</td>\n",
              "      <td>-1.613642</td>\n",
              "      <td>1.484188</td>\n",
              "      <td>-0.113277</td>\n",
              "      <td>-0.251152</td>\n",
              "      <td>0.179023</td>\n",
              "      <td>-0.233104</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009842</td>\n",
              "      <td>0.054811</td>\n",
              "      <td>0.003233</td>\n",
              "      <td>0.031708</td>\n",
              "      <td>0.015571</td>\n",
              "      <td>-0.004691</td>\n",
              "      <td>0.043818</td>\n",
              "      <td>0.003463</td>\n",
              "      <td>-0.027180</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>923</th>\n",
              "      <td>-1.321884</td>\n",
              "      <td>2.153021</td>\n",
              "      <td>0.788596</td>\n",
              "      <td>-1.304253</td>\n",
              "      <td>0.458186</td>\n",
              "      <td>-0.859346</td>\n",
              "      <td>-0.069127</td>\n",
              "      <td>-0.392796</td>\n",
              "      <td>0.755732</td>\n",
              "      <td>-0.584050</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.037611</td>\n",
              "      <td>0.078257</td>\n",
              "      <td>-0.043549</td>\n",
              "      <td>-0.030543</td>\n",
              "      <td>0.008307</td>\n",
              "      <td>-0.027181</td>\n",
              "      <td>-0.049055</td>\n",
              "      <td>-0.010741</td>\n",
              "      <td>0.011886</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>924</th>\n",
              "      <td>-0.867163</td>\n",
              "      <td>-0.040504</td>\n",
              "      <td>0.940680</td>\n",
              "      <td>0.302648</td>\n",
              "      <td>-0.469672</td>\n",
              "      <td>-0.368255</td>\n",
              "      <td>1.065579</td>\n",
              "      <td>0.801522</td>\n",
              "      <td>0.690113</td>\n",
              "      <td>0.953008</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012459</td>\n",
              "      <td>-0.094131</td>\n",
              "      <td>0.012074</td>\n",
              "      <td>-0.028681</td>\n",
              "      <td>-0.007974</td>\n",
              "      <td>0.061485</td>\n",
              "      <td>-0.007939</td>\n",
              "      <td>-0.062855</td>\n",
              "      <td>-0.020197</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>925</th>\n",
              "      <td>3.753012</td>\n",
              "      <td>0.841636</td>\n",
              "      <td>-0.317393</td>\n",
              "      <td>-0.296117</td>\n",
              "      <td>0.593769</td>\n",
              "      <td>-0.255474</td>\n",
              "      <td>-0.057091</td>\n",
              "      <td>-0.072048</td>\n",
              "      <td>0.664386</td>\n",
              "      <td>-0.837668</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.008577</td>\n",
              "      <td>-0.005870</td>\n",
              "      <td>-0.003372</td>\n",
              "      <td>0.003218</td>\n",
              "      <td>-0.019323</td>\n",
              "      <td>0.066904</td>\n",
              "      <td>0.021464</td>\n",
              "      <td>-0.001711</td>\n",
              "      <td>-0.011906</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>926</th>\n",
              "      <td>0.603083</td>\n",
              "      <td>0.126259</td>\n",
              "      <td>0.003433</td>\n",
              "      <td>0.283612</td>\n",
              "      <td>0.169559</td>\n",
              "      <td>-0.156326</td>\n",
              "      <td>-0.068399</td>\n",
              "      <td>-0.184308</td>\n",
              "      <td>0.461063</td>\n",
              "      <td>-0.002047</td>\n",
              "      <td>...</td>\n",
              "      <td>0.056610</td>\n",
              "      <td>0.024137</td>\n",
              "      <td>-0.014507</td>\n",
              "      <td>-0.081209</td>\n",
              "      <td>-0.000572</td>\n",
              "      <td>0.030829</td>\n",
              "      <td>-0.056736</td>\n",
              "      <td>0.021194</td>\n",
              "      <td>0.066228</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>927</th>\n",
              "      <td>-1.452945</td>\n",
              "      <td>1.233599</td>\n",
              "      <td>0.439472</td>\n",
              "      <td>0.278517</td>\n",
              "      <td>0.165928</td>\n",
              "      <td>-0.171830</td>\n",
              "      <td>-0.075000</td>\n",
              "      <td>0.033859</td>\n",
              "      <td>0.004444</td>\n",
              "      <td>-0.687583</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012713</td>\n",
              "      <td>-0.031891</td>\n",
              "      <td>0.069221</td>\n",
              "      <td>-0.062677</td>\n",
              "      <td>0.013343</td>\n",
              "      <td>-0.074262</td>\n",
              "      <td>0.005516</td>\n",
              "      <td>-0.055673</td>\n",
              "      <td>-0.029486</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>928 rows × 101 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25a3e7c4-17ce-4ff6-a78d-c68e995fe066')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-25a3e7c4-17ce-4ff6-a78d-c68e995fe066 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-25a3e7c4-17ce-4ff6-a78d-c68e995fe066');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UOI2lH6iOIY"
      },
      "source": [
        "#### **TRYING DIFFERENT ML MODELS ON A SINGLE LEAD(EX : 1) POST DIMENSIONALITY REDUCTION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE3l8LNQizo0"
      },
      "source": [
        "##### **KNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Me4jqP4Zih_I",
        "outputId": "57200b48-8a8d-42a9-acaf-d3cb6e1580ff"
      },
      "source": [
        "# Import the necessary modules for ML model\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Setup the pipeline steps:\n",
        "steps = [('knn', KNeighborsClassifier())]\n",
        "        \n",
        "# Create the pipeline: pipeline \n",
        "pipeline = Pipeline(steps)\n",
        "\n",
        "# have paased less range value of hyperparamter since i'm using free tier version of google colab.\n",
        "k_range = list(range(1, 9))\n",
        "parameters = dict(knn__n_neighbors=k_range)\n",
        "\n",
        "#input\n",
        "X = result_df.iloc[:,0:-1]\n",
        "\n",
        "#target\n",
        "y=result_df.iloc[:,-1]\n",
        "\n",
        "# Create train and test sets \n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4,random_state=42)\n",
        "\n",
        "#increasing cv score takes lot of time in gooogle colab, so kept it just 2.\n",
        "cv = GridSearchCV(pipeline,parameters,cv=2)\n",
        "\n",
        "cv.fit(X_train,y_train)\n",
        "\n",
        "# Predict the labels of the test set: y_pred\n",
        "y_pred = cv.predict(X_test)\n",
        "\n",
        "Knn_Accuracy = cv.score(X_test, y_test)\n",
        "\n",
        "# Compute and print metrics\n",
        "print(\"Accuracy: {}\".format(Knn_Accuracy))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Tuned Model Parameters: {}\".format(cv.best_params_))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.782258064516129\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.63      0.73       105\n",
            "           1       0.91      0.91      0.91        94\n",
            "           2       0.72      0.88      0.79       112\n",
            "           3       0.63      0.67      0.65        61\n",
            "\n",
            "    accuracy                           0.78       372\n",
            "   macro avg       0.78      0.77      0.77       372\n",
            "weighted avg       0.80      0.78      0.78       372\n",
            "\n",
            "Tuned Model Parameters: {'knn__n_neighbors': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDkFlXChia-8"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKtMbgXLifbX"
      },
      "source": [
        "##### **LOGISTIC REGRESSION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbGt_eOVkJq6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1212215d-184f-4879-acd3-00c5104a1404"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Setup the pipeline steps:\n",
        "steps = [('lr', LogisticRegression())]\n",
        "        \n",
        "# Create the pipeline: pipeline \n",
        "pipeline = Pipeline(steps)\n",
        "\n",
        "#input\n",
        "X = result_df.iloc[:,0:-1]\n",
        "\n",
        "#target\n",
        "y=result_df.iloc[:,-1]\n",
        "\n",
        "#parameters for gridsearchcv if we increase range of entries from 5 to higher value, we can get greater accurange\n",
        "c_space = np.logspace(-4, 4, 3)\n",
        "parameters = {'lr__C': c_space,'lr__penalty': ['l2']} \n",
        "\n",
        "# Create train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4,random_state=42)\n",
        "\n",
        "#call GridSearchCV and set crossvalscore to 2\n",
        "cv = GridSearchCV(pipeline,parameters,cv=2)\n",
        "\n",
        "cv.fit(X_train,y_train)\n",
        "\n",
        "# Predict the labels of the test set: y_pred\n",
        "y_pred = cv.predict(X_test)\n",
        "LR_Accuracy = cv.score(X_test, y_test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3k9i12eGunX1",
        "outputId": "ab5788f1-12cc-40df-834c-2df59f8af3a4"
      },
      "source": [
        "# Compute and print metrics\n",
        "print(\"Accuracy: {}\".format(LR_Accuracy))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Tuned Model Parameters: {}\".format(cv.best_params_))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.553763440860215\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.33      0.36       105\n",
            "           1       0.73      0.91      0.81        94\n",
            "           2       0.57      0.59      0.58       112\n",
            "           3       0.41      0.31      0.36        61\n",
            "\n",
            "    accuracy                           0.55       372\n",
            "   macro avg       0.52      0.54      0.53       372\n",
            "weighted avg       0.53      0.55      0.54       372\n",
            "\n",
            "Tuned Model Parameters: {'lr__C': 10000.0, 'lr__penalty': 'l2'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W0sQQDwiisE"
      },
      "source": [
        "##### **SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94xczE1iurC9",
        "outputId": "34f22dfd-5b9c-4ba9-95d8-223f20a0bf69"
      },
      "source": [
        "# Import the necessary modules for ML model\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Setup the pipeline\n",
        "steps = [('SVM', SVC())]\n",
        "\n",
        "pipeline = Pipeline(steps)\n",
        "\n",
        "#input\n",
        "X = result_df.iloc[:,0:-1]\n",
        "\n",
        "#target\n",
        "y=result_df.iloc[:,-1]\n",
        "\n",
        "# Specify the hyperparameter space, if we increase the penalty(c) and gamma value the accurancy can be increased.\n",
        "#since it takes lots of time in google colab provided only a single value\n",
        "parameters = {'SVM__C':[10],'SVM__gamma':[1]}\n",
        "\n",
        "# Create train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4,random_state=21)\n",
        "\n",
        "cv = GridSearchCV(pipeline,parameters,cv=3)\n",
        "cv.fit(X_train,y_train)\n",
        "\n",
        "y_pred = cv.predict(X_test)\n",
        "SVM_Accuracy = cv.score(X_test, y_test)\n",
        "\n",
        "# Compute and print metrics\n",
        "SVM_Accuracy=cv.score(X_test, y_test)\n",
        "\n",
        "print(\"Accuracy: {}\".format(SVM_Accuracy))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8225806451612904\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      1.00      0.74        93\n",
            "           1       1.00      1.00      1.00        99\n",
            "           2       1.00      0.61      0.76       117\n",
            "           3       1.00      0.68      0.81        63\n",
            "\n",
            "    accuracy                           0.82       372\n",
            "   macro avg       0.90      0.82      0.83       372\n",
            "weighted avg       0.90      0.82      0.83       372\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1GNZtOUi6PP"
      },
      "source": [
        "#### **NOW COMBINING ALL 12 LEADS INTO A SINGLE CSV FILE AND THEN PERFROM MODEL ANALYSIS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "huNy0hsWSkr5",
        "outputId": "dfc874bd-3553-433e-daea-0471dea72fe2"
      },
      "source": [
        "#lets try combining all 12 leads in a single csv\n",
        "location= '/39120047'\n",
        "for files in natsorted(os.listdir(location)):\n",
        "  if files.endswith(\".csv\") and not files.endswith(\"13.csv\"):\n",
        "    if files!='Combined_IDLead_1.csv':\n",
        "     # df=pd.read_csv('/39120047')\n",
        "      #df.drop(columns=['Unnamed: 0'],inplace=True)\n",
        "      test_final=pd.concat([test_final,df],axis=1,ignore_index=True)\n",
        "      test_final.drop(columns=test_final.columns[-1],axis=1,inplace=True)\n",
        "\n",
        "#drop the target column\n",
        "test_final.drop(columns=[255],axis=1,inplace=True)\n",
        "test_final"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2         3         4         5         6    \\\n",
              "0    0.728449  0.680755  0.619010  0.645367  0.681570  0.732488  0.758448   \n",
              "1    0.957972  0.950695  0.941024  0.930501  0.913601  0.892244  0.868016   \n",
              "2    0.611084  0.661575  0.695790  0.741113  0.716666  0.595794  0.425022   \n",
              "3    0.839213  0.861690  0.866457  0.865756  0.855027  0.855606  0.845561   \n",
              "4    0.917753  0.924369  0.873765  0.791381  0.699513  0.604927  0.500312   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "923  0.874246  0.877014  0.864280  0.860505  0.871349  0.912404  0.958148   \n",
              "924  0.829815  0.832084  0.852396  0.909665  0.988242  1.000000  0.923323   \n",
              "925  0.469048  0.417983  0.362322  0.351995  0.391493  0.418305  0.440135   \n",
              "926  0.682510  0.682286  0.641051  0.620212  0.608210  0.576331  0.603596   \n",
              "927  0.792175  0.815695  0.819518  0.820559  0.847985  0.880933  0.902061   \n",
              "\n",
              "          7         8         9    ...       501       502       503  \\\n",
              "0    0.750660  0.728282  0.707928  ...  0.618500  0.637260  0.664539   \n",
              "1    0.855127  0.835307  0.798640  ...  0.720793  0.778790  0.806883   \n",
              "2    0.286457  0.425022  0.611384  ...  0.133674  0.000000  0.042690   \n",
              "3    0.843187  0.846784  0.824438  ...  0.759995  0.789156  0.793622   \n",
              "4    0.446012  0.528910  0.634068  ...  0.100169  0.200676  0.300147   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "923  0.977826  0.956314  0.926773  ...  0.879619  0.908312  0.926328   \n",
              "924  0.821865  0.721302  0.612039  ...  0.321041  0.429721  0.531567   \n",
              "925  0.444598  0.460402  0.506810  ...  0.434073  0.408587  0.401864   \n",
              "926  0.645714  0.677964  0.720297  ...  0.500438  0.452247  0.450421   \n",
              "927  0.878266  0.838806  0.811795  ...  0.700667  0.737351  0.778845   \n",
              "\n",
              "          504       505       506       507       508       509       510  \n",
              "0    0.667226  0.637064  0.593287  0.545503  0.515049  0.563257  0.633581  \n",
              "1    0.818640  0.842472  0.866740  0.884152  0.897196  0.911293  0.922903  \n",
              "2    0.165850  0.363445  0.549460  0.539346  0.522272  0.491668  0.454949  \n",
              "3    0.787665  0.794515  0.796739  0.804063  0.809944  0.801814  0.777322  \n",
              "4    0.407225  0.507346  0.605953  0.699309  0.790334  0.856593  0.849957  \n",
              "..        ...       ...       ...       ...       ...       ...       ...  \n",
              "923  0.898749  0.855709  0.823132  0.815458  0.818083  0.829300  0.822382  \n",
              "924  0.642137  0.742063  0.833042  0.814867  0.777622  0.760714  0.759294  \n",
              "925  0.387069  0.359590  0.325879  0.288894  0.293521  0.344504  0.399012  \n",
              "926  0.439278  0.439086  0.394417  0.441650  0.473909  0.539199  0.547146  \n",
              "927  0.805446  0.782640  0.751236  0.741331  0.718790  0.714504  0.691004  \n",
              "\n",
              "[928 rows x 510 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e74c9d6e-270b-4cd9-acd1-7805d3a2af24\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>501</th>\n",
              "      <th>502</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.728449</td>\n",
              "      <td>0.680755</td>\n",
              "      <td>0.619010</td>\n",
              "      <td>0.645367</td>\n",
              "      <td>0.681570</td>\n",
              "      <td>0.732488</td>\n",
              "      <td>0.758448</td>\n",
              "      <td>0.750660</td>\n",
              "      <td>0.728282</td>\n",
              "      <td>0.707928</td>\n",
              "      <td>...</td>\n",
              "      <td>0.618500</td>\n",
              "      <td>0.637260</td>\n",
              "      <td>0.664539</td>\n",
              "      <td>0.667226</td>\n",
              "      <td>0.637064</td>\n",
              "      <td>0.593287</td>\n",
              "      <td>0.545503</td>\n",
              "      <td>0.515049</td>\n",
              "      <td>0.563257</td>\n",
              "      <td>0.633581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.957972</td>\n",
              "      <td>0.950695</td>\n",
              "      <td>0.941024</td>\n",
              "      <td>0.930501</td>\n",
              "      <td>0.913601</td>\n",
              "      <td>0.892244</td>\n",
              "      <td>0.868016</td>\n",
              "      <td>0.855127</td>\n",
              "      <td>0.835307</td>\n",
              "      <td>0.798640</td>\n",
              "      <td>...</td>\n",
              "      <td>0.720793</td>\n",
              "      <td>0.778790</td>\n",
              "      <td>0.806883</td>\n",
              "      <td>0.818640</td>\n",
              "      <td>0.842472</td>\n",
              "      <td>0.866740</td>\n",
              "      <td>0.884152</td>\n",
              "      <td>0.897196</td>\n",
              "      <td>0.911293</td>\n",
              "      <td>0.922903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.611084</td>\n",
              "      <td>0.661575</td>\n",
              "      <td>0.695790</td>\n",
              "      <td>0.741113</td>\n",
              "      <td>0.716666</td>\n",
              "      <td>0.595794</td>\n",
              "      <td>0.425022</td>\n",
              "      <td>0.286457</td>\n",
              "      <td>0.425022</td>\n",
              "      <td>0.611384</td>\n",
              "      <td>...</td>\n",
              "      <td>0.133674</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.042690</td>\n",
              "      <td>0.165850</td>\n",
              "      <td>0.363445</td>\n",
              "      <td>0.549460</td>\n",
              "      <td>0.539346</td>\n",
              "      <td>0.522272</td>\n",
              "      <td>0.491668</td>\n",
              "      <td>0.454949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.839213</td>\n",
              "      <td>0.861690</td>\n",
              "      <td>0.866457</td>\n",
              "      <td>0.865756</td>\n",
              "      <td>0.855027</td>\n",
              "      <td>0.855606</td>\n",
              "      <td>0.845561</td>\n",
              "      <td>0.843187</td>\n",
              "      <td>0.846784</td>\n",
              "      <td>0.824438</td>\n",
              "      <td>...</td>\n",
              "      <td>0.759995</td>\n",
              "      <td>0.789156</td>\n",
              "      <td>0.793622</td>\n",
              "      <td>0.787665</td>\n",
              "      <td>0.794515</td>\n",
              "      <td>0.796739</td>\n",
              "      <td>0.804063</td>\n",
              "      <td>0.809944</td>\n",
              "      <td>0.801814</td>\n",
              "      <td>0.777322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.917753</td>\n",
              "      <td>0.924369</td>\n",
              "      <td>0.873765</td>\n",
              "      <td>0.791381</td>\n",
              "      <td>0.699513</td>\n",
              "      <td>0.604927</td>\n",
              "      <td>0.500312</td>\n",
              "      <td>0.446012</td>\n",
              "      <td>0.528910</td>\n",
              "      <td>0.634068</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100169</td>\n",
              "      <td>0.200676</td>\n",
              "      <td>0.300147</td>\n",
              "      <td>0.407225</td>\n",
              "      <td>0.507346</td>\n",
              "      <td>0.605953</td>\n",
              "      <td>0.699309</td>\n",
              "      <td>0.790334</td>\n",
              "      <td>0.856593</td>\n",
              "      <td>0.849957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>923</th>\n",
              "      <td>0.874246</td>\n",
              "      <td>0.877014</td>\n",
              "      <td>0.864280</td>\n",
              "      <td>0.860505</td>\n",
              "      <td>0.871349</td>\n",
              "      <td>0.912404</td>\n",
              "      <td>0.958148</td>\n",
              "      <td>0.977826</td>\n",
              "      <td>0.956314</td>\n",
              "      <td>0.926773</td>\n",
              "      <td>...</td>\n",
              "      <td>0.879619</td>\n",
              "      <td>0.908312</td>\n",
              "      <td>0.926328</td>\n",
              "      <td>0.898749</td>\n",
              "      <td>0.855709</td>\n",
              "      <td>0.823132</td>\n",
              "      <td>0.815458</td>\n",
              "      <td>0.818083</td>\n",
              "      <td>0.829300</td>\n",
              "      <td>0.822382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>924</th>\n",
              "      <td>0.829815</td>\n",
              "      <td>0.832084</td>\n",
              "      <td>0.852396</td>\n",
              "      <td>0.909665</td>\n",
              "      <td>0.988242</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.923323</td>\n",
              "      <td>0.821865</td>\n",
              "      <td>0.721302</td>\n",
              "      <td>0.612039</td>\n",
              "      <td>...</td>\n",
              "      <td>0.321041</td>\n",
              "      <td>0.429721</td>\n",
              "      <td>0.531567</td>\n",
              "      <td>0.642137</td>\n",
              "      <td>0.742063</td>\n",
              "      <td>0.833042</td>\n",
              "      <td>0.814867</td>\n",
              "      <td>0.777622</td>\n",
              "      <td>0.760714</td>\n",
              "      <td>0.759294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>925</th>\n",
              "      <td>0.469048</td>\n",
              "      <td>0.417983</td>\n",
              "      <td>0.362322</td>\n",
              "      <td>0.351995</td>\n",
              "      <td>0.391493</td>\n",
              "      <td>0.418305</td>\n",
              "      <td>0.440135</td>\n",
              "      <td>0.444598</td>\n",
              "      <td>0.460402</td>\n",
              "      <td>0.506810</td>\n",
              "      <td>...</td>\n",
              "      <td>0.434073</td>\n",
              "      <td>0.408587</td>\n",
              "      <td>0.401864</td>\n",
              "      <td>0.387069</td>\n",
              "      <td>0.359590</td>\n",
              "      <td>0.325879</td>\n",
              "      <td>0.288894</td>\n",
              "      <td>0.293521</td>\n",
              "      <td>0.344504</td>\n",
              "      <td>0.399012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>926</th>\n",
              "      <td>0.682510</td>\n",
              "      <td>0.682286</td>\n",
              "      <td>0.641051</td>\n",
              "      <td>0.620212</td>\n",
              "      <td>0.608210</td>\n",
              "      <td>0.576331</td>\n",
              "      <td>0.603596</td>\n",
              "      <td>0.645714</td>\n",
              "      <td>0.677964</td>\n",
              "      <td>0.720297</td>\n",
              "      <td>...</td>\n",
              "      <td>0.500438</td>\n",
              "      <td>0.452247</td>\n",
              "      <td>0.450421</td>\n",
              "      <td>0.439278</td>\n",
              "      <td>0.439086</td>\n",
              "      <td>0.394417</td>\n",
              "      <td>0.441650</td>\n",
              "      <td>0.473909</td>\n",
              "      <td>0.539199</td>\n",
              "      <td>0.547146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>927</th>\n",
              "      <td>0.792175</td>\n",
              "      <td>0.815695</td>\n",
              "      <td>0.819518</td>\n",
              "      <td>0.820559</td>\n",
              "      <td>0.847985</td>\n",
              "      <td>0.880933</td>\n",
              "      <td>0.902061</td>\n",
              "      <td>0.878266</td>\n",
              "      <td>0.838806</td>\n",
              "      <td>0.811795</td>\n",
              "      <td>...</td>\n",
              "      <td>0.700667</td>\n",
              "      <td>0.737351</td>\n",
              "      <td>0.778845</td>\n",
              "      <td>0.805446</td>\n",
              "      <td>0.782640</td>\n",
              "      <td>0.751236</td>\n",
              "      <td>0.741331</td>\n",
              "      <td>0.718790</td>\n",
              "      <td>0.714504</td>\n",
              "      <td>0.691004</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>928 rows × 510 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e74c9d6e-270b-4cd9-acd1-7805d3a2af24')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e74c9d6e-270b-4cd9-acd1-7805d3a2af24 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e74c9d6e-270b-4cd9-acd1-7805d3a2af24');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ6_Lg0180y3"
      },
      "source": [
        "#write the file to csv\n",
        "test_final.to_csv('final_1D.csv',header=False,index=False)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxWK-X-qjde2"
      },
      "source": [
        "#### **TEST DIMENSIONALITY REDUCTION EXPLAINED VARIANCE ON  THE DATA**\n",
        "**NOTE: CURRENTLY NOT USED IN THE FINAL TEST MODEL **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXvZGdh5cxrL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "24fd5f0c-8202-40bf-fe66-06742102c9da"
      },
      "source": [
        "# Now Perform Dimensionality reduction (PCA) on that Dataframe and check\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#do PCA and choose componeents as 400\n",
        "pca = PCA(n_components=400)\n",
        "x_pca = pca.fit_transform(test_final)\n",
        "x_pca = pd.DataFrame(x_pca)\n",
        "\n",
        "# Calculate the variance explained by priciple components\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "print('Variance of each component:', pca.explained_variance_ratio_)\n",
        "print('\\n Total Variance Explained:', round(sum(list(pca.explained_variance_ratio_))*100, 2))\n",
        "\n",
        "#store the new pca generated dimensions in a dataframe\n",
        "#store the new pca generated dimensions in a dataframe\n",
        "pca_df = pd.DataFrame(data = x_pca)\n",
        "target = pd.Series(result_df.iloc[:,-1], name='target')\n",
        "final_result_df = pd.concat([pca_df, target], axis=1)\n",
        "final_result_df"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variance of each component: [1.76145888e-01 9.50265614e-02 6.99060614e-02 6.15960001e-02\n",
            " 5.34876630e-02 4.23664893e-02 3.68320213e-02 3.38541791e-02\n",
            " 3.00884979e-02 2.90396728e-02 2.64962509e-02 2.42272738e-02\n",
            " 2.10221030e-02 1.99751559e-02 1.77321042e-02 1.63016802e-02\n",
            " 1.53898622e-02 1.48412074e-02 1.33644825e-02 1.19674074e-02\n",
            " 1.16813409e-02 1.05807650e-02 9.68875480e-03 9.47385060e-03\n",
            " 8.65347748e-03 8.47506998e-03 7.93382172e-03 7.30163338e-03\n",
            " 6.76380665e-03 6.36886390e-03 6.02004791e-03 5.46823032e-03\n",
            " 5.31229911e-03 4.97821789e-03 4.74686092e-03 4.46081684e-03\n",
            " 4.21254684e-03 4.01200243e-03 3.87246476e-03 3.52519084e-03\n",
            " 3.37596894e-03 3.26978336e-03 3.08241145e-03 2.96423495e-03\n",
            " 2.73419816e-03 2.50965698e-03 2.35335480e-03 2.25665349e-03\n",
            " 2.20141761e-03 1.96782025e-03 1.74343954e-03 1.70982830e-03\n",
            " 1.57456047e-03 1.53704487e-03 1.36768435e-03 1.33167096e-03\n",
            " 1.26444173e-03 1.20053330e-03 1.18738749e-03 1.08864087e-03\n",
            " 1.02824532e-03 9.11484783e-04 7.89962329e-04 7.59785111e-04\n",
            " 6.49920865e-04 6.27833793e-04 6.04784065e-04 5.45886709e-04\n",
            " 5.32310105e-04 4.97728351e-04 4.78393197e-04 4.50404969e-04\n",
            " 4.26173491e-04 4.09392372e-04 3.92601465e-04 3.70241597e-04\n",
            " 3.66854853e-04 3.38846664e-04 3.08205859e-04 3.00634282e-04\n",
            " 2.80363597e-04 2.67851114e-04 2.49661250e-04 2.40639048e-04\n",
            " 2.11564526e-04 2.03939902e-04 1.99025594e-04 1.83142589e-04\n",
            " 1.66820017e-04 1.65885594e-04 1.55974779e-04 1.39182689e-04\n",
            " 1.25356243e-04 1.22364999e-04 1.13683177e-04 1.09489649e-04\n",
            " 1.03516326e-04 9.94209262e-05 9.87155690e-05 9.45513565e-05\n",
            " 8.84533091e-05 8.10962058e-05 7.22879154e-05 7.09106563e-05\n",
            " 6.85659514e-05 6.61579104e-05 6.24305178e-05 5.98719714e-05\n",
            " 5.92288919e-05 5.52417424e-05 5.25771509e-05 4.93405691e-05\n",
            " 4.63403200e-05 4.26211204e-05 4.06136710e-05 3.98147794e-05\n",
            " 3.77065064e-05 3.71114834e-05 3.56777167e-05 3.35208082e-05\n",
            " 3.13206393e-05 3.05281324e-05 2.99640795e-05 2.87288956e-05\n",
            " 2.71846531e-05 2.64848078e-05 2.45139291e-05 2.37756821e-05\n",
            " 2.29003072e-05 2.20148410e-05 2.12514230e-05 2.04358230e-05\n",
            " 1.93775184e-05 1.85935041e-05 1.82988231e-05 1.73869546e-05\n",
            " 1.70149189e-05 1.59260642e-05 1.55775375e-05 1.50838043e-05\n",
            " 1.48295884e-05 1.38927462e-05 1.36503252e-05 1.30903266e-05\n",
            " 1.23148238e-05 1.17613976e-05 1.15354304e-05 1.10467119e-05\n",
            " 1.03501835e-05 1.01796528e-05 9.72389346e-06 9.28709398e-06\n",
            " 9.17693595e-06 8.95557107e-06 8.77565392e-06 8.46066753e-06\n",
            " 8.04307490e-06 7.73643018e-06 7.46137455e-06 7.43408114e-06\n",
            " 6.96951787e-06 6.86318563e-06 6.58745637e-06 6.29891493e-06\n",
            " 6.10772997e-06 6.06988524e-06 5.92737912e-06 5.68576871e-06\n",
            " 5.40226664e-06 5.20320502e-06 5.10228027e-06 4.71708727e-06\n",
            " 4.69971429e-06 4.58116324e-06 4.49558553e-06 4.28119918e-06\n",
            " 4.24412799e-06 4.11230101e-06 3.93188748e-06 3.86633112e-06\n",
            " 3.74182082e-06 3.59904676e-06 3.58932101e-06 3.41276341e-06\n",
            " 3.36438041e-06 3.23967276e-06 3.14671873e-06 2.97286232e-06\n",
            " 2.91312278e-06 2.85321674e-06 2.66070233e-06 2.60522291e-06\n",
            " 2.51775991e-06 2.38258253e-06 2.35505291e-06 2.26059530e-06\n",
            " 2.20803768e-06 2.11080017e-06 2.01115265e-06 2.00334181e-06\n",
            " 1.89581253e-06 1.85773100e-06 1.82689378e-06 1.77412258e-06\n",
            " 1.74742233e-06 1.67701543e-06 1.62456563e-06 1.60798883e-06\n",
            " 1.55971674e-06 1.53591781e-06 1.49768360e-06 1.45595384e-06\n",
            " 1.40275364e-06 1.34923751e-06 1.30307737e-06 1.24829287e-06\n",
            " 1.21610919e-06 1.16640645e-06 1.15153519e-06 1.13228976e-06\n",
            " 1.11950664e-06 1.09394559e-06 1.06580045e-06 1.00731247e-06\n",
            " 9.74100243e-07 9.45692823e-07 9.18002419e-07 8.78857943e-07\n",
            " 8.59299198e-07 8.40851865e-07 7.97849799e-07 7.73482565e-07\n",
            " 7.65507913e-07 7.44092126e-07 7.17408198e-07 7.05043468e-07\n",
            " 6.55013197e-07 6.32938538e-07 6.15978875e-07 5.80210296e-07\n",
            " 5.62493988e-07 5.52910813e-07 5.40389478e-07 4.89198475e-07\n",
            " 4.76176389e-07 4.63498785e-07 4.42985954e-07 4.26171602e-07\n",
            " 4.13430549e-07 3.83093327e-07 3.65057501e-07 3.48128137e-07\n",
            " 3.23131802e-07 3.01036143e-07 2.63295372e-07 3.47386512e-32\n",
            " 1.75641896e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33\n",
            " 1.75640732e-33 1.75640732e-33 1.75640732e-33 1.75640732e-33]\n",
            "\n",
            " Total Variance Explained: 100.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6  \\\n",
              "0    1.440486  1.623890 -0.833795  0.273815  0.067812 -0.437558 -0.228489   \n",
              "1   -1.553785  0.409885 -2.498050  1.521928 -0.369394 -1.160285 -0.670603   \n",
              "2    0.388938 -0.638219  0.150968 -0.603041  0.093526  0.979306  0.897876   \n",
              "3   -2.145483  2.351403 -1.444148  1.137405 -0.398786  0.732818  0.503104   \n",
              "4   -0.216148 -1.479667  0.496782  1.556174 -2.282035  2.098959 -0.160197   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "923 -1.869426  3.044831  1.115244 -1.844493  0.647973 -1.215299 -0.097761   \n",
              "924 -1.226353 -0.057282  1.330323  0.428009 -0.664217 -0.520791  1.506956   \n",
              "925  5.307560  1.190253 -0.448861 -0.418773  0.839716 -0.361294 -0.080738   \n",
              "926  0.852888  0.178557  0.004855  0.401088  0.239793 -0.221079 -0.096731   \n",
              "927 -2.054775  1.744573  0.621507  0.393883  0.234657 -0.243004 -0.106066   \n",
              "\n",
              "            7         8         9  ...           391           392  \\\n",
              "0    0.676660  1.375186 -0.045017  ...  1.229889e-16  1.307040e-17   \n",
              "1   -0.728657  0.979186  2.123592  ... -1.303108e-17  2.637110e-16   \n",
              "2   -0.050723  1.153794 -1.286189  ... -1.411004e-16 -3.510669e-16   \n",
              "3   -0.486822 -1.288160 -0.890271  ...  3.457440e-16  3.855139e-16   \n",
              "4   -0.355182  0.253177 -0.329658  ...  2.565552e-17 -5.295420e-16   \n",
              "..        ...       ...       ...  ...           ...           ...   \n",
              "923 -0.555497  1.068766 -0.825972  ... -1.625125e-16 -4.927451e-16   \n",
              "924  1.133523  0.975968  1.347757  ... -8.622863e-17 -2.696999e-16   \n",
              "925 -0.101891  0.939584 -1.184641  ...  1.694587e-16 -8.057713e-18   \n",
              "926 -0.260651  0.652042 -0.002895  ...  1.826064e-16  7.395005e-17   \n",
              "927  0.047884  0.006285 -0.972389  ...  3.985737e-17 -2.896034e-16   \n",
              "\n",
              "              393           394           395           396           397  \\\n",
              "0    8.954586e-17 -1.889339e-16  1.447202e-17 -2.063713e-16 -1.890370e-16   \n",
              "1    5.848173e-17  4.719974e-16  3.308482e-16 -4.116368e-16 -4.562251e-16   \n",
              "2    3.136150e-16  7.519161e-16 -6.828135e-16  1.057452e-16 -2.519751e-16   \n",
              "3    3.218618e-16 -1.301715e-16 -2.011851e-16  2.383955e-17  3.370842e-16   \n",
              "4    2.516383e-16 -7.416585e-17 -1.966532e-16  7.532424e-16  2.981064e-16   \n",
              "..            ...           ...           ...           ...           ...   \n",
              "923 -1.141755e-16 -2.670549e-16  1.081338e-16 -1.644252e-16  3.735182e-16   \n",
              "924 -5.831796e-17 -2.228308e-16  2.767539e-16  3.049326e-16  3.611583e-16   \n",
              "925 -2.315705e-17 -1.106884e-18  1.932106e-16 -2.000197e-16 -1.721446e-17   \n",
              "926 -7.326591e-17  5.407869e-18  2.144523e-16  4.412274e-17 -1.519605e-17   \n",
              "927 -1.918906e-17 -8.026667e-17 -1.539341e-16  6.112504e-17 -3.390392e-16   \n",
              "\n",
              "              398           399  target  \n",
              "0   -4.790693e-17  3.469536e-16       2  \n",
              "1   -3.494174e-16  9.047841e-17       2  \n",
              "2    2.805934e-16  2.115965e-16       2  \n",
              "3    1.990169e-16 -3.036319e-16       2  \n",
              "4    2.280966e-16 -4.143663e-16       2  \n",
              "..            ...           ...     ...  \n",
              "923 -8.088216e-17  1.156898e-16       3  \n",
              "924 -1.752265e-17  2.609930e-16       3  \n",
              "925 -8.784748e-17  1.503800e-16       3  \n",
              "926  2.902474e-16  1.077746e-17       3  \n",
              "927  1.512398e-16 -2.705705e-17       3  \n",
              "\n",
              "[928 rows x 401 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac62c26e-3d99-4339-8639-1775cf120b01\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>391</th>\n",
              "      <th>392</th>\n",
              "      <th>393</th>\n",
              "      <th>394</th>\n",
              "      <th>395</th>\n",
              "      <th>396</th>\n",
              "      <th>397</th>\n",
              "      <th>398</th>\n",
              "      <th>399</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.440486</td>\n",
              "      <td>1.623890</td>\n",
              "      <td>-0.833795</td>\n",
              "      <td>0.273815</td>\n",
              "      <td>0.067812</td>\n",
              "      <td>-0.437558</td>\n",
              "      <td>-0.228489</td>\n",
              "      <td>0.676660</td>\n",
              "      <td>1.375186</td>\n",
              "      <td>-0.045017</td>\n",
              "      <td>...</td>\n",
              "      <td>1.229889e-16</td>\n",
              "      <td>1.307040e-17</td>\n",
              "      <td>8.954586e-17</td>\n",
              "      <td>-1.889339e-16</td>\n",
              "      <td>1.447202e-17</td>\n",
              "      <td>-2.063713e-16</td>\n",
              "      <td>-1.890370e-16</td>\n",
              "      <td>-4.790693e-17</td>\n",
              "      <td>3.469536e-16</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.553785</td>\n",
              "      <td>0.409885</td>\n",
              "      <td>-2.498050</td>\n",
              "      <td>1.521928</td>\n",
              "      <td>-0.369394</td>\n",
              "      <td>-1.160285</td>\n",
              "      <td>-0.670603</td>\n",
              "      <td>-0.728657</td>\n",
              "      <td>0.979186</td>\n",
              "      <td>2.123592</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.303108e-17</td>\n",
              "      <td>2.637110e-16</td>\n",
              "      <td>5.848173e-17</td>\n",
              "      <td>4.719974e-16</td>\n",
              "      <td>3.308482e-16</td>\n",
              "      <td>-4.116368e-16</td>\n",
              "      <td>-4.562251e-16</td>\n",
              "      <td>-3.494174e-16</td>\n",
              "      <td>9.047841e-17</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.388938</td>\n",
              "      <td>-0.638219</td>\n",
              "      <td>0.150968</td>\n",
              "      <td>-0.603041</td>\n",
              "      <td>0.093526</td>\n",
              "      <td>0.979306</td>\n",
              "      <td>0.897876</td>\n",
              "      <td>-0.050723</td>\n",
              "      <td>1.153794</td>\n",
              "      <td>-1.286189</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.411004e-16</td>\n",
              "      <td>-3.510669e-16</td>\n",
              "      <td>3.136150e-16</td>\n",
              "      <td>7.519161e-16</td>\n",
              "      <td>-6.828135e-16</td>\n",
              "      <td>1.057452e-16</td>\n",
              "      <td>-2.519751e-16</td>\n",
              "      <td>2.805934e-16</td>\n",
              "      <td>2.115965e-16</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-2.145483</td>\n",
              "      <td>2.351403</td>\n",
              "      <td>-1.444148</td>\n",
              "      <td>1.137405</td>\n",
              "      <td>-0.398786</td>\n",
              "      <td>0.732818</td>\n",
              "      <td>0.503104</td>\n",
              "      <td>-0.486822</td>\n",
              "      <td>-1.288160</td>\n",
              "      <td>-0.890271</td>\n",
              "      <td>...</td>\n",
              "      <td>3.457440e-16</td>\n",
              "      <td>3.855139e-16</td>\n",
              "      <td>3.218618e-16</td>\n",
              "      <td>-1.301715e-16</td>\n",
              "      <td>-2.011851e-16</td>\n",
              "      <td>2.383955e-17</td>\n",
              "      <td>3.370842e-16</td>\n",
              "      <td>1.990169e-16</td>\n",
              "      <td>-3.036319e-16</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.216148</td>\n",
              "      <td>-1.479667</td>\n",
              "      <td>0.496782</td>\n",
              "      <td>1.556174</td>\n",
              "      <td>-2.282035</td>\n",
              "      <td>2.098959</td>\n",
              "      <td>-0.160197</td>\n",
              "      <td>-0.355182</td>\n",
              "      <td>0.253177</td>\n",
              "      <td>-0.329658</td>\n",
              "      <td>...</td>\n",
              "      <td>2.565552e-17</td>\n",
              "      <td>-5.295420e-16</td>\n",
              "      <td>2.516383e-16</td>\n",
              "      <td>-7.416585e-17</td>\n",
              "      <td>-1.966532e-16</td>\n",
              "      <td>7.532424e-16</td>\n",
              "      <td>2.981064e-16</td>\n",
              "      <td>2.280966e-16</td>\n",
              "      <td>-4.143663e-16</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>923</th>\n",
              "      <td>-1.869426</td>\n",
              "      <td>3.044831</td>\n",
              "      <td>1.115244</td>\n",
              "      <td>-1.844493</td>\n",
              "      <td>0.647973</td>\n",
              "      <td>-1.215299</td>\n",
              "      <td>-0.097761</td>\n",
              "      <td>-0.555497</td>\n",
              "      <td>1.068766</td>\n",
              "      <td>-0.825972</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.625125e-16</td>\n",
              "      <td>-4.927451e-16</td>\n",
              "      <td>-1.141755e-16</td>\n",
              "      <td>-2.670549e-16</td>\n",
              "      <td>1.081338e-16</td>\n",
              "      <td>-1.644252e-16</td>\n",
              "      <td>3.735182e-16</td>\n",
              "      <td>-8.088216e-17</td>\n",
              "      <td>1.156898e-16</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>924</th>\n",
              "      <td>-1.226353</td>\n",
              "      <td>-0.057282</td>\n",
              "      <td>1.330323</td>\n",
              "      <td>0.428009</td>\n",
              "      <td>-0.664217</td>\n",
              "      <td>-0.520791</td>\n",
              "      <td>1.506956</td>\n",
              "      <td>1.133523</td>\n",
              "      <td>0.975968</td>\n",
              "      <td>1.347757</td>\n",
              "      <td>...</td>\n",
              "      <td>-8.622863e-17</td>\n",
              "      <td>-2.696999e-16</td>\n",
              "      <td>-5.831796e-17</td>\n",
              "      <td>-2.228308e-16</td>\n",
              "      <td>2.767539e-16</td>\n",
              "      <td>3.049326e-16</td>\n",
              "      <td>3.611583e-16</td>\n",
              "      <td>-1.752265e-17</td>\n",
              "      <td>2.609930e-16</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>925</th>\n",
              "      <td>5.307560</td>\n",
              "      <td>1.190253</td>\n",
              "      <td>-0.448861</td>\n",
              "      <td>-0.418773</td>\n",
              "      <td>0.839716</td>\n",
              "      <td>-0.361294</td>\n",
              "      <td>-0.080738</td>\n",
              "      <td>-0.101891</td>\n",
              "      <td>0.939584</td>\n",
              "      <td>-1.184641</td>\n",
              "      <td>...</td>\n",
              "      <td>1.694587e-16</td>\n",
              "      <td>-8.057713e-18</td>\n",
              "      <td>-2.315705e-17</td>\n",
              "      <td>-1.106884e-18</td>\n",
              "      <td>1.932106e-16</td>\n",
              "      <td>-2.000197e-16</td>\n",
              "      <td>-1.721446e-17</td>\n",
              "      <td>-8.784748e-17</td>\n",
              "      <td>1.503800e-16</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>926</th>\n",
              "      <td>0.852888</td>\n",
              "      <td>0.178557</td>\n",
              "      <td>0.004855</td>\n",
              "      <td>0.401088</td>\n",
              "      <td>0.239793</td>\n",
              "      <td>-0.221079</td>\n",
              "      <td>-0.096731</td>\n",
              "      <td>-0.260651</td>\n",
              "      <td>0.652042</td>\n",
              "      <td>-0.002895</td>\n",
              "      <td>...</td>\n",
              "      <td>1.826064e-16</td>\n",
              "      <td>7.395005e-17</td>\n",
              "      <td>-7.326591e-17</td>\n",
              "      <td>5.407869e-18</td>\n",
              "      <td>2.144523e-16</td>\n",
              "      <td>4.412274e-17</td>\n",
              "      <td>-1.519605e-17</td>\n",
              "      <td>2.902474e-16</td>\n",
              "      <td>1.077746e-17</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>927</th>\n",
              "      <td>-2.054775</td>\n",
              "      <td>1.744573</td>\n",
              "      <td>0.621507</td>\n",
              "      <td>0.393883</td>\n",
              "      <td>0.234657</td>\n",
              "      <td>-0.243004</td>\n",
              "      <td>-0.106066</td>\n",
              "      <td>0.047884</td>\n",
              "      <td>0.006285</td>\n",
              "      <td>-0.972389</td>\n",
              "      <td>...</td>\n",
              "      <td>3.985737e-17</td>\n",
              "      <td>-2.896034e-16</td>\n",
              "      <td>-1.918906e-17</td>\n",
              "      <td>-8.026667e-17</td>\n",
              "      <td>-1.539341e-16</td>\n",
              "      <td>6.112504e-17</td>\n",
              "      <td>-3.390392e-16</td>\n",
              "      <td>1.512398e-16</td>\n",
              "      <td>-2.705705e-17</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>928 rows × 401 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac62c26e-3d99-4339-8639-1775cf120b01')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ac62c26e-3d99-4339-8639-1775cf120b01 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ac62c26e-3d99-4339-8639-1775cf120b01');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l93cv3DXjw2A"
      },
      "source": [
        "#### **TRYING DIFFERENT ML MODELS ON THE ALL 12 LEADS COMBINED FILE WITHOUT DIMENSIONALITY REDUCTION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLAdjoV0j5oS"
      },
      "source": [
        "##### **KNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np5A0l30TYEI",
        "outputId": "d1dc2878-d469-4b5c-d49e-2138eb99c30d"
      },
      "source": [
        "# Import the necessary modules for ML model\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Setup the pipeline steps:\n",
        "steps = [('knn', KNeighborsClassifier())]\n",
        "        \n",
        "# Create the pipeline: pipeline \n",
        "pipeline = Pipeline(steps)\n",
        "\n",
        "# have paased less range value of hyperparamter since i'm using free tier version of google colab.\n",
        "k_range = list(range(1, 30))\n",
        "parameters = dict(knn__n_neighbors=k_range)\n",
        "\n",
        "#input\n",
        "X = pd.read_csv('final_1D.csv',header=None)\n",
        "\n",
        "#target\n",
        "y=final_result_df.iloc[:,-1]\n",
        "\n",
        "# Create train and test sets \n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4,random_state=42)\n",
        "\n",
        "#increasing cv score takes lot of time in gooogle colab, so kept it just 2.\n",
        "cv = GridSearchCV(pipeline,parameters,cv=2)\n",
        "\n",
        "cv.fit(X_train,y_train)\n",
        "\n",
        "# Predict the labels of the test set: y_pred\n",
        "y_pred = cv.predict(X_test)\n",
        "\n",
        "Knn_Accuracy = cv.score(X_test, y_test)\n",
        "\n",
        "# Compute and print metrics\n",
        "print(\"Accuracy: {}\".format(Knn_Accuracy))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Tuned Model Parameters: {}\".format(cv.best_params_))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7795698924731183\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.62      0.72       105\n",
            "           1       0.91      0.91      0.91        94\n",
            "           2       0.71      0.88      0.78       112\n",
            "           3       0.63      0.67      0.65        61\n",
            "\n",
            "    accuracy                           0.78       372\n",
            "   macro avg       0.78      0.77      0.77       372\n",
            "weighted avg       0.79      0.78      0.78       372\n",
            "\n",
            "Tuned Model Parameters: {'knn__n_neighbors': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "METf9MJdkESh"
      },
      "source": [
        "##### **LOGISTIC REGRESSION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qBayEUskDfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa33183b-0ea6-40e1-a8bb-246b39587470"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Setup the pipeline steps:\n",
        "steps = [('lr', LogisticRegression())]\n",
        "        \n",
        "# Create the pipeline: pipeline \n",
        "pipeline = Pipeline(steps)\n",
        "\n",
        "#input\n",
        "X = pd.read_csv('final_1D.csv',header=None)\n",
        "\n",
        "#target\n",
        "y=final_result_df.iloc[:,-1]\n",
        "\n",
        "#parameters for gridsearchcv\n",
        "c_space = np.logspace(-4, 4, 10)\n",
        "parameters = {'lr__C': c_space,'lr__penalty': ['l2']} \n",
        "\n",
        "# Create train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4,random_state=42)\n",
        "\n",
        "#call GridSearchCV and set crossvalscore to 2\n",
        "cv = GridSearchCV(pipeline,parameters,cv=2)\n",
        "\n",
        "cv.fit(X_train,y_train)\n",
        "\n",
        "# Predict the labels of the test set: y_pred\n",
        "y_pred = cv.predict(X_test)\n",
        "LR_Accuracy = cv.score(X_test, y_test)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xV9YlHZktj9",
        "outputId": "f713cc49-47c6-4005-9a08-4abe5a38840a"
      },
      "source": [
        "# Compute and print metrics\n",
        "print(\"Accuracy: {}\".format(LR_Accuracy))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Tuned Model Parameters: {}\".format(cv.best_params_))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4731182795698925\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.38      0.39       105\n",
            "           1       0.56      0.73      0.63        94\n",
            "           2       0.50      0.46      0.47       112\n",
            "           3       0.35      0.26      0.30        61\n",
            "\n",
            "    accuracy                           0.47       372\n",
            "   macro avg       0.45      0.46      0.45       372\n",
            "weighted avg       0.46      0.47      0.46       372\n",
            "\n",
            "Tuned Model Parameters: {'lr__C': 21.54434690031882, 'lr__penalty': 'l2'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOJDLUA6p5Xd"
      },
      "source": [
        "##### **SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yG0rz8crlJK5",
        "outputId": "2c94b39f-88db-47a1-be9e-7571a2a9c838"
      },
      "source": [
        "# Import the necessary modules for ML model\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Setup the pipeline\n",
        "steps = [('SVM', SVC())]\n",
        "\n",
        "pipeline = Pipeline(steps)\n",
        "\n",
        "#input\n",
        "X = pd.read_csv('final_1D.csv',header=None)\n",
        "\n",
        "#target\n",
        "y=final_result_df.iloc[:,-1]\n",
        "\n",
        "# Specify the hyperparameter space, if we increase the penalty(c) and gamma value the accurancy can be increased.\n",
        "#since it takes lots of time in google colab provided only a single value\n",
        "parameters = {'SVM__C':[1, 10, 100],\n",
        "              'SVM__gamma':[0.1, 0.01]}\n",
        "\n",
        "# Create train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.5,random_state=21)\n",
        "\n",
        "cv = GridSearchCV(pipeline,parameters,cv=3)\n",
        "cv.fit(X_train,y_train)\n",
        "\n",
        "y_pred = cv.predict(X_test)\n",
        "SVM_Accuracy = cv.score(X_test, y_test)\n",
        "\n",
        "# Compute and print metrics\n",
        "SVM_Accuracy=cv.score(X_test, y_test)\n",
        "\n",
        "print(\"Accuracy: {}\".format(SVM_Accuracy))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8405172413793104\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.85      0.83       119\n",
            "           1       0.98      1.00      0.99       125\n",
            "           2       0.85      0.79      0.81       140\n",
            "           3       0.66      0.68      0.67        80\n",
            "\n",
            "    accuracy                           0.84       464\n",
            "   macro avg       0.82      0.83      0.83       464\n",
            "weighted avg       0.84      0.84      0.84       464\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izUvTTDBp-Vy"
      },
      "source": [
        "#### **SAVING A VERY BASIC ML MODEL AND USING IT ON REALTIME PIPELINE TO CHECK WORKING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mN7RIL_3PnJb",
        "outputId": "309f574c-e017-44c2-db64-db1819649b0a"
      },
      "source": [
        "# Import the necessary modules for ML model\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import joblib\n",
        "#input\n",
        "X = pd.read_csv('final_1D.csv',header=None)\n",
        "\n",
        "#target\n",
        "y=final_result_df.iloc[:,-1]\n",
        "\n",
        "# Create train and test sets \n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4,random_state=42)\n",
        "\n",
        "knn =  KNeighborsClassifier(n_neighbors=1)\n",
        "\n",
        "knn.fit(X_train,y_train)\n",
        "\n",
        "joblib_file='model_test.pkl'\n",
        "joblib.dump(knn,joblib_file)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model_test.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Emu__tW7qP9b"
      },
      "source": [
        "## SAVE AND USE THE ABOVE MODEL IN THE STREAMLIT APP : **https://colab.research.google.com/drive/139YVmcUBCiP52J2sX3QE_eiu2sukVgpn?usp=sharing**"
      ]
    }
  ]
}